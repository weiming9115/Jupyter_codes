{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### numpy array version for composite code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat\n",
    "from cartopy.util import add_cyclic_point\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import warnings\n",
    "import psutil\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib import patches\n",
    "from matplotlib import cm\n",
    "\n",
    "from metpy import calc as mpcalc\n",
    "from metpy.units import units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#os.chdir('/w2-data2/willytsai/python_module/')\n",
    "os.chdir('/data2/willytsai/python_module/')\n",
    "import SCAI_calc4obj as scai\n",
    "import conorgidx_revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# MERRA2_dir = '/w2-data2/willytsai/MERRA2/'\n",
    "# Gridsat_dir = '/w2-data/willytsai/gridsat_BT/remap_0.25deg/'\n",
    "ISCCP_dir = '/data/willytsai/ISCCP/hgg/'\n",
    "# MERRA2_3d_dir = '/w2-data/willytsai/TQUV_3hr/'\n",
    "MERRA2_dir = '/data2/willytsai/MERRA2/'\n",
    "Gridsat_dir = '/data/willytsai/gridsat_BT/remap_0.1deg/'\n",
    "ISCCP_dir = '/data/willytsai/ISCCP/hgg/'\n",
    "MERRA2_3d_dir = '/data/willytsai/TQUV_3hr/'\n",
    "MERRA2_TQCI_dir = '/data/willytsai/TQCI_3hr'\n",
    "AIRS_dir = '/data/willytsai/AIRS_daily'\n",
    "TRMM_dir = '/data2/willytsai/TRMM_3hr/TRMM/'\n",
    "WHOI_dir = '/data/willytsai/WHOI_oaflux/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def event_region(lat_event,lon_event,lon_w,lon_e):\n",
    "    'select specfic region'\n",
    "    idx = np.where(np.logical_and(lon_event >= lon_w, lon_event <= lon_e))[0]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def subset_MERRA2(file_path,time_cent,lat_cent,lon_cent,days=3,lat_inc=5,lon_inc=5):\n",
    "\n",
    "    os.chdir(file_path)\n",
    "    \n",
    "    n=0\n",
    "    # daily file \n",
    "    date_sel = [time_cent + timedelta(days=day) for day in range(-days,days+1)] # selected files\n",
    "    for i,date in enumerate(date_sel):\n",
    "        #print(date)\n",
    "        date_str = datetime.strftime(date,format='%Y%m%d')\n",
    "        file = sorted(glob('*'+date_str+'*'))[0]\n",
    "        data = xr.open_dataset(file)\n",
    "        data = data.sel(lat=slice(lat_cent-lat_inc,lat_cent+lat_inc),\n",
    "                        lon=slice(lon_cent-lon_inc,lon_cent+lon_inc))\n",
    "        \n",
    "        if n == 0: \n",
    "            tmp = data; n+=1\n",
    "        else:\n",
    "            tmp = xr.concat([tmp,data],'time')\n",
    "    \n",
    "    # extract fetched time window \n",
    "    data_sub = tmp.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "    \n",
    "    return data_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_ISCCP(file_path,time_cent,lat_cent,lon_cent,days=3,lat_inc=5,lon_inc=5):\n",
    "    os.chdir(file_path)\n",
    "\n",
    "    n=0\n",
    "    # daily file \n",
    "    date_sel = [time_cent + timedelta(days=day) for day in range(-days,days+1)] # selected files\n",
    "    for i,date in enumerate(date_sel):\n",
    "        #print(date)\n",
    "        date_str = datetime.strftime(date,format='%Y.%m.%d')\n",
    "        files = sorted(glob('*'+date_str+'*'))\n",
    "        for file in files:\n",
    "            data = xr.open_dataset(file)\n",
    "            if lon_cent < 0: \n",
    "                lon_cent = 180 + (180 + lon_cent) # -180,180 to ISCCP lon ranging from 0 to 360\n",
    "            data = data.sel(lat=slice(lat_cent-lat_inc,lat_cent+lat_inc),\n",
    "                            lon=slice(lon_cent-lon_inc,lon_cent+lon_inc))\n",
    "\n",
    "            # extract specific cloud types \n",
    "            cldamt_call = data.cldamt\n",
    "            cldamt_call = cldamt_call.where(cldamt_call<=100,np.nan); #keep values <= 100\n",
    "            \n",
    "            cldamt_type = data.cldamt_types   \n",
    "            cldamt_cu = (cldamt_type[0,0,:,:]+cldamt_type[0,3,:,:])\n",
    "            cldamt_cu = cldamt_cu.where(cldamt_cu<=100,np.nan); \n",
    "            cldamt_st = (cldamt_type[0,13,:,:]+cldamt_type[0,16,:,:])\n",
    "            cldamt_st = cldamt_st.where(cldamt_st<=100,np.nan)\n",
    "            cldamt_dc = (cldamt_type[0,14,:,:]+cldamt_type[0,17,:,:])\n",
    "            cldamt_dc = cldamt_dc.where(cldamt_dc<=100,np.nan)\n",
    "        \n",
    "            if n == 0: \n",
    "                tmp0 = cldamt_call;\n",
    "                tmp1 = cldamt_cu; \n",
    "                tmp2 = cldamt_st; \n",
    "                tmp3 = cldamt_dc; n+=1\n",
    "            \n",
    "            else:\n",
    "                tmp0 = xr.concat([tmp0,cldamt_call],'time')\n",
    "                tmp1 = xr.concat([tmp1,cldamt_cu],'time')\n",
    "                tmp2 = xr.concat([tmp2,cldamt_st],'time')\n",
    "                tmp3 = xr.concat([tmp3,cldamt_dc],'time')\n",
    "\n",
    "    # extract fetched time window \n",
    "    call_sub = tmp0.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "    cu_sub = tmp1.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "    st_sub = tmp2.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "    dc_sub = tmp3.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "\n",
    "    return call_sub,cu_sub,st_sub,dc_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def subset_ISCCP(file_path,time_cent,lat_cent,lon_cent,days=3,lat_inc=5,lon_inc=5):\n",
    "#     os.chdir(file_path)\n",
    "\n",
    "#     n=0\n",
    "#     # daily file \n",
    "#     date_sel = [time_cent + timedelta(days=day) for day in range(-days,days+1)] # selected files\n",
    "#     for i,date in enumerate(date_sel):\n",
    "#         #print(date)\n",
    "#         date_str = datetime.strftime(date,format='%Y.%m.%d')\n",
    "#         files = sorted(glob('*'+date_str+'*'))\n",
    "#         for file in files:\n",
    "#             data = xr.open_dataset(file)\n",
    "#             if lon_cent < 0: \n",
    "#                 lon_cent = 180 + (180 + lon_cent) # -180,180 to ISCCP lon ranging from 0 to 360\n",
    "#             data = data.sel(lat=slice(lat_cent-lat_inc,lat_cent+lat_inc),\n",
    "#                             lon=slice(lon_cent-lon_inc,lon_cent+lon_inc))\n",
    "\n",
    "#             # extract specific cloud types \n",
    "#             cldamt_call = data.cldamt_ir\n",
    "#             cldamt_call = cldamt_call[0,:,:]\n",
    "#             cldamt_call = cldamt_call.where(cldamt_call<=100,np.nan); #keep values <= 100\n",
    "            \n",
    "#             cldamt_type = data.cldamt_irtypes   \n",
    "#             cldamt_low = cldamt_type[0,0,:,:]\n",
    "#             cldamt_low = cldamt_low.where(cldamt_low<=100,np.nan); \n",
    "#             cldamt_mid = cldamt_type[0,1,:,:]\n",
    "#             cldamt_mid = cldamt_mid.where(cldamt_mid<=100,np.nan)\n",
    "#             cldamt_high = cldamt_type[0,2,:,:]\n",
    "#             cldamt_high = cldamt_high.where(cldamt_high<=100,np.nan)\n",
    "        \n",
    "#             if n == 0: \n",
    "#                 tmp0 = cldamt_call;\n",
    "#                 tmp1 = cldamt_low; \n",
    "#                 tmp2 = cldamt_mid; \n",
    "#                 tmp3 = cldamt_high; n+=1\n",
    "            \n",
    "#             else:\n",
    "#                 tmp0 = xr.concat([tmp0,cldamt_call],'time')\n",
    "#                 tmp1 = xr.concat([tmp1,cldamt_low],'time')\n",
    "#                 tmp2 = xr.concat([tmp2,cldamt_mid],'time')\n",
    "#                 tmp3 = xr.concat([tmp3,cldamt_high],'time')\n",
    "\n",
    "#     # extract fetched time window \n",
    "#     call_sub = tmp0.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "#     low_sub = tmp1.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "#     mid_sub = tmp2.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "#     high_sub = tmp3.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "\n",
    "#     return call_sub,low_sub,mid_sub,high_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_ISCCP_pc(file_path,time_cent,lat_cent,lon_cent,days=3,lat_inc=5,lon_inc=5):\n",
    "    os.chdir(file_path)\n",
    "\n",
    "    n=0\n",
    "    # daily file \n",
    "    date_sel = [time_cent + timedelta(days=day) for day in range(-days,days+1)] # selected files\n",
    "    for i,date in enumerate(date_sel):\n",
    "        #print(date)\n",
    "        date_str = datetime.strftime(date,format='%Y.%m.%d')\n",
    "        files = sorted(glob('*'+date_str+'*'))\n",
    "        for file in files:\n",
    "            data = xr.open_dataset(file)\n",
    "            if lon_cent < 0: \n",
    "                lon_cent = 180 + (180 + lon_cent) # ISCCP lon ranges from 0 to 360\n",
    "            data = data.sel(lat=slice(lat_cent-lat_inc,lat_cent+lat_inc),\n",
    "                            lon=slice(lon_cent-lon_inc,lon_cent+lon_inc))\n",
    "\n",
    "            # extract mean cloud top pressure\n",
    "            ctp = data.pc_ir  \n",
    "        \n",
    "            if n == 0: \n",
    "                tmp = ctp; n+=1\n",
    "            \n",
    "            else:\n",
    "                tmp = xr.concat([tmp,ctp],'time')\n",
    "\n",
    "    # extract fetched time window \n",
    "    ctp_sub = tmp.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "\n",
    "    return ctp_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_TRMM(file_path,time_cent,lat_cent,lon_cent,days=3,lat_inc=5,lon_inc=5):\n",
    "\n",
    "    os.chdir(file_path)\n",
    "    \n",
    "    n=0\n",
    "    # daily file\n",
    "    date_sel = [time_cent + timedelta(days=day) for day in range(-days,days+1)] # selected files\n",
    "    for i,date in enumerate(date_sel):\n",
    "        date_str = datetime.strftime(date,format='%Y%m%d')\n",
    "        files = sorted(glob('*'+date_str+'*')) # sub-daily\n",
    "        for file in files:\n",
    "            data = xr.open_dataset(file)\n",
    "            data = data.sel(nlat=slice(lat_cent-lat_inc,lat_cent+lat_inc),\n",
    "                            nlon=slice(lon_cent-lon_inc,lon_cent+lon_inc))\n",
    "            data = data.assign_coords(time=datetime.strptime(file[5:16],'%Y%m%d.%H'))\n",
    "        \n",
    "            if n == 0: \n",
    "                tmp = data; n+=1\n",
    "            else:\n",
    "                tmp = xr.concat([tmp,data],dim='time')\n",
    "    \n",
    "    # extract fetched time window \n",
    "    data_sub = tmp.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "    \n",
    "    return data_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_gridsat(file_path,time_cent,lat_cent,lon_cent,days=3,lat_inc=5,lon_inc=5):\n",
    "\n",
    "    os.chdir(file_path)\n",
    "    \n",
    "    n=0\n",
    "    # daily file\n",
    "    date_sel = [time_cent + timedelta(days=day) for day in range(-days,days+1)] # selected files\n",
    "    for i,date in enumerate(date_sel):\n",
    "        date_str = datetime.strftime(date,format='%Y.%m.%d')\n",
    "        files = sorted(glob('*'+date_str+'*')) # sub-daily\n",
    "        for file in files:\n",
    "            data = xr.open_dataset(file)\n",
    "            data = data.sel(lat=slice(lat_cent-lat_inc,lat_cent+lat_inc)\n",
    "                            ,lon=slice(lon_cent-lon_inc,lon_cent+lon_inc))\n",
    "            data = data.assign_coords(time=datetime.strptime(file[11:24],'%Y.%m.%d.%H'))\n",
    "        \n",
    "            if n == 0: \n",
    "                tmp = data; n+=1\n",
    "            else:\n",
    "                tmp = xr.concat([tmp,data],'time')\n",
    "    \n",
    "    # extract fetched time window \n",
    "    data_sub = tmp.sel(time=slice(time_cent-timedelta(days=days),time_cent+timedelta(days=days)))\n",
    "    \n",
    "    return data_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_AIRS(file_path,time_cent,lat_cent,lon_cent,days=3,lat_inc=5,lon_inc=5):\n",
    "    \n",
    "    os.chdir(file_path)\n",
    "    \n",
    "    n=0\n",
    "    # daily file\n",
    "    date_sel = [time_cent + timedelta(days=day) for day in range(-days,days+1)] # selected files\n",
    "    for i,date in enumerate(date_sel):\n",
    "        date_str = datetime.strftime(date,format='%Y.%m.%d')\n",
    "        files = sorted(glob('*'+date_str+'*')) # sub-daily\n",
    "        for file in files:\n",
    "            data = xr.open_dataset(file)\n",
    "            data = data.sel(Latitude=slice(lat_cent+lat_inc,lat_cent-lat_inc)\n",
    "                            ,Longitude=slice(lon_cent-lon_inc,lon_cent+lon_inc))\n",
    "            data = data.assign_coords(time=datetime.strptime(file[5:15],'%Y.%m.%d'))\n",
    "        \n",
    "            if n == 0: \n",
    "                tmp = data; n+=1\n",
    "            else:\n",
    "                tmp = xr.concat([tmp,data],'time')\n",
    "    \n",
    "    # extract fetched time window \n",
    "    data_sub = tmp\n",
    "    \n",
    "    return data_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_CERES(file_path,time_cent,lat_cent,lon_cent,days=2,lat_inc=5,lon_inc=5):\n",
    "    os.chdir(file_path)\n",
    "    \n",
    "    # daily file\n",
    "    date_sel = [time_cent + timedelta(days=day) for day in range(-days,days+1)] # selected files\n",
    "    data = xr.open_dataset('CERES_SYN1deg-3H_2014_2018.nc')\n",
    "    if lon_cent <= 0: \n",
    "        lon_cent = 180 + (180 + lon_cent) # CERES lon ranges from 0 to 360\n",
    "        data = data.sel(lat=slice(lat_cent-lat_inc,lat_cent+lat_inc),\n",
    "                        lon=slice(lon_cent-lon_inc,lon_cent+lon_inc),\n",
    "                        time=slice(date_sel[0],date_sel[-1]))\n",
    "    else:\n",
    "        data = data.sel(lat=slice(lat_cent-lat_inc,lat_cent+lat_inc),\n",
    "                        lon=slice(lon_cent-lon_inc,lon_cent+lon_inc),\n",
    "                        time=slice(date_sel[0],date_sel[-1]))\n",
    "    \n",
    "    # extract fetched time window \n",
    "    data_sub = data\n",
    "    \n",
    "    return data_sub    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_WHOI(file_path,time_cent,lat_cent,lon_cent,days=2,lat_inc=5,lon_inc=5):\n",
    "    os.chdir(file_path)\n",
    "    \n",
    "    time_cent_new = time_cent.replace(hour=0)\n",
    "    date_sel = [time_cent_new + timedelta(days=day) for day in range(-days,days+1)] # selected files\n",
    "    data = evap_xr\n",
    "    if lon_cent <= 0: \n",
    "        lon_cent = 180 + (180 + lon_cent) # CERES lon ranges from 0 to 360\n",
    "        data = data.sel(lat=slice(lat_cent-lat_inc,lat_cent+lat_inc),\n",
    "                        lon=slice(lon_cent-lon_inc,lon_cent+lon_inc),\n",
    "                        time=slice(date_sel[0],date_sel[-1]))\n",
    "    else:\n",
    "        data = data.sel(lat=slice(lat_cent-lat_inc,lat_cent+lat_inc),\n",
    "                        lon=slice(lon_cent-lon_inc,lon_cent+lon_inc),\n",
    "                        time=slice(date_sel[0],date_sel[-1]))\n",
    "    \n",
    "    # extract fetched time window \n",
    "    data_sub = data\n",
    "    \n",
    "    return data_sub    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCAI_index_bt(bt_sm,cri_val=240):\n",
    "\n",
    "    N_psT = np.zeros(bt_sm.shape[0]) # BT_based\n",
    "    SCAI_BT = np.zeros(bt_sm.shape[0]) # cldfrac over domain by BT criteria\n",
    "    \n",
    "   # N and SCAI indices\n",
    "    for t in range(bt_sm.shape[0]):\n",
    "        label_obj, N = scai.labeled_obj(bt_sm[t,:,:].values,cri=cri_val,flag=2) # less than 240 K\n",
    "        label_new, num_new = scai.label_remove(label_obj, N, connect_min=3) # remove obj with pixel numb. < 3\n",
    "        SCAI_BT[t] = scai.SCAI_calc(label_new,num_new,dx=0.1*100000,L=5*100000)\n",
    "        N_psT[t] = num_new\n",
    "\n",
    "    return (SCAI_BT,N_psT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Iorg_index_bt(bt_sm):\n",
    "\n",
    "    Iorg_BT = np.zeros(bt_sm.shape[0]) # cldfrac over domain by BT criteria\n",
    "    \n",
    "   # Iorg calculation\n",
    "    for t in range(bt_sm.shape[0]):\n",
    "        cldmask = bt_sm[t,:,:].values\n",
    "        cldmask[cldmask>240] = np.nan # maskout bt > 240K\n",
    "        try:\n",
    "            Iorg_BT[t] = conorgidx_revise.iorg(cldmask)\n",
    "        except:\n",
    "            Iorg_BT[t] = np.nan\n",
    "       \n",
    "    return (Iorg_BT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_case(time_event,lon_event,lat_event,cri_r=300,ratio=0.5):\n",
    "    'precipitation area is enclosed within a circle R at reference time'\n",
    "    \n",
    "    file_path = TRMM_dir+'2014_2018'\n",
    "    time_cent = time_event\n",
    "    lat_cent = lat_event\n",
    "    lon_cent = lon_event\n",
    "    \n",
    "    # read preciptation data in the given domain\n",
    "    data = subset_TRMM(file_path,time_cent,lat_cent,lon_cent,days=0,lat_inc=2.5,lon_inc=2.5)\n",
    "    prec_sm = data.precipitation.squeeze()\n",
    "    prec_sum = np.nansum(prec_sm)\n",
    "\n",
    "    # calculate the distance matrix\n",
    "    x,y = np.meshgrid(prec_sm.nlon,prec_sm.nlat)\n",
    "    dist = np.sqrt((x-lon_cent)**2+(y-lat_cent)**2)*100 # distance from center [km]\n",
    "    prec_sm.values[dist > cri_r] = 0\n",
    "    prec_frac = (np.nansum(prec_sm)/prec_sum)\n",
    "    \n",
    "    if prec_frac >= ratio:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test ISCCP\n",
    "# os.chdir('/data/willytsai/ISCCP/hgg')\n",
    "# data = xr.open_dataset('ISCCP-Basic.HGG.v01r00.GLOBAL.2015.02.25.1200.GPC.10KM.CS00.EA1.00.nc')\n",
    "# # lon_re = np.linspace(0.5,179.5,180,dtype=np.float32); lon_re2 = np.linspace(-179.5,-0.5,180,dtype=np.float32)\n",
    "# # lon_rst = np.concatenate((lon_re,lon_re2)) # reconstruct longitude coordinate\n",
    "# # data_re = data.assign_coords(lon=lon_rst)\n",
    "\n",
    "# cldamt_type = data.sel(lat=slice(-10,0),lon=slice(210,220)).cldamt_types\n",
    "# cldamt_cu = (cldamt_type[0,0,:,:]+cldamt_type[0,3,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "#os.chdir('/w2-data/willytsai/ISCCP/')\n",
    "os.chdir('/data/willytsai/ISCCP/')\n",
    "\n",
    "# variable namelist\n",
    "var_name = np.loadtxt('var_name_2014_2018_5deg_4ds_M2.dat',dtype='U16')\n",
    "# event time\n",
    "var_time = np.loadtxt('time_event_2014_2018_5deg_4ds_M2.dat',dtype='U13')\n",
    "time_event = []\n",
    "for t in var_time:\n",
    "    tmp = datetime.strptime(t,'%Y-%m-%d-%H')\n",
    "    time_event.append(tmp)\n",
    "\n",
    "var_dataset = (np.loadtxt('var_event_2014_2018_5deg_4ds_M2.dat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# precipitation events over specific basins: \n",
    "lat_event = var_dataset[:,0]\n",
    "lon_event = var_dataset[:,1]\n",
    "idx_REG = event_region(lat_event,lon_event,-180,180) # all tropics\n",
    "\n",
    "# total event over IND\n",
    "time_event = np.asarray(time_event); time_event = time_event[idx_REG]\n",
    "lat_event = var_dataset[idx_REG,0]\n",
    "lon_event = var_dataset[idx_REG,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_org = np.where(lat_event>-50)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79994"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(y,window_N):\n",
    "    y_avg = np.zeros(len(y))\n",
    "    avg_mask = np.ones(window_N) / window_N\n",
    "    y_avg = np.convolve(y, avg_mask, 'same')\n",
    "    return y_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.85 s, sys: 2.97 s, total: 6.83 s\n",
      "Wall time: 33min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    data_sub = subset_TRMM(TRMM_dir+'2009_2018'\n",
    "                          ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                            lat_inc=2.5,lon_inc=2.5)\n",
    "    prec_sm = data_sub.precipitation\n",
    "    prec_org = np.nanmean(prec_sm,axis=(1,2))\n",
    "    \n",
    "    return (prec_org)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_org = np.zeros((len(t_org),33))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = len(time_result[n])\n",
    "    if tmp ==33:\n",
    "        prec_org[n,:tmp] = time_result[n]\n",
    "    else:\n",
    "        prec_org[n,:tmp] = np.nan\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('prec_all_5deg_4ds_M2.mat.npy',prec_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    data_sub7 = subset_MERRA2(MERRA2_3d_dir+'../Preci_3hr'\n",
    "                        ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                        lat_inc=2.5,lon_inc=2.5)\n",
    "\n",
    "    precM2_sm = data_sub7.PRECTOT.resample(time='3H').nearest()   \n",
    "    precM2_org = np.nanmean(precM2_sm,axis=(1,2))\n",
    "    \n",
    "    return (precM2_org)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precM2_org = np.zeros((len(t_org),32))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = len(time_result[n])\n",
    "    precM2_org[n,:tmp] = time_result[n]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('precM2_all_5deg_4ds_M2.mat.npy',precM2_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "\n",
    "    bt_sub = subset_gridsat(Gridsat_dir+'2009_2018',time_event[t],lat_event[t],lon_event[t],days=2\n",
    "                                        ,lat_inc=2.5,lon_inc=2.5)\n",
    "    bt_sm = bt_sub.irwin_cdr\n",
    "    SCAI_BT,N_psT = SCAI_index_bt(bt_sm,cri_val=240)\n",
    "    cldfrac_sm = [len(np.where(bt_sm[n,:,:] < 240)[0])/(len(bt_sm.lat)*len(bt_sm.lon)) for n in range(33)]\n",
    "    \n",
    "    return SCAI_BT, N_psT, cldfrac_sm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCAI_org = np.zeros((len(t_org),33))\n",
    "N_org = np.zeros((len(t_org),33))\n",
    "cldfrac_org = np.zeros((len(t_org),33))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = len(time_result[n][0])\n",
    "    SCAI_org[n,:tmp] = time_result[n][0]\n",
    "    N_org[n,:tmp] = time_result[n][1]\n",
    "    cldfrac_org[n,:tmp] = np.asarray(time_result[n][2])\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('SCAIbt_all_5deg_4ds_M2.mat.npy',SCAI_org)\n",
    "np.save('N_all_5deg_4ds_M2.mat.npy',N_org)\n",
    "np.save('cldfrac_all_5deg_4ds_M2.mat.npy',cldfrac_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "\n",
    "    rh_sub = subset_MERRA2('/data/willytsai/RH_3hr_p',time_event[t],lat_event[t],lon_event[t],days=2\n",
    "                                        ,lat_inc=2.5,lon_inc=2.5)\n",
    "    rh_sm = rh_sub.RH.values\n",
    "    rh = np.nanmean(rh_sm,axis=(2,3))\n",
    "    \n",
    "    return (rh)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_org = np.zeros((len(t_org),33,42))*np.nan\n",
    "for n in range(len(t_org)):\n",
    "    tmp = time_result[n].shape[0]\n",
    "    rh_org[n,:tmp,:] = time_result[n]\n",
    "    \n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('rh_all_5deg_4ds_M2.mat.npy',rh_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    data_sub = subset_CERES('/data/willytsai/CERES/'\n",
    "                          ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                            lat_inc=2.5,lon_inc=2.5)\n",
    "    \n",
    "    swup_toa = np.nanmean(data_sub.adj_atmos_sw_up_all_toa_3h,axis=(1,2))\n",
    "    swup_sfc = np.nanmean(data_sub.adj_atmos_sw_up_all_surface_3h,axis=(1,2))\n",
    "    swdown_toa = np.nanmean(data_sub.adj_atmos_sw_down_all_toa_3h,axis=(1,2))\n",
    "    swdown_sfc = np.nanmean(data_sub.adj_atmos_sw_down_all_surface_3h,axis=(1,2))\n",
    "    lwup_toa = np.nanmean(data_sub.adj_atmos_lw_up_all_toa_3h,axis=(1,2))        \n",
    "    lwup_sfc = np.nanmean(data_sub.adj_atmos_lw_up_all_surface_3h,axis=(1,2))  \n",
    "    lwdown_toa = np.nanmean(data_sub.adj_atmos_lw_down_all_toa_3h,axis=(1,2))      \n",
    "    lwdown_sfc = np.nanmean(data_sub.adj_atmos_lw_down_all_surface_3h,axis=(1,2))  \n",
    "\n",
    "    # net atmosphere radiation \n",
    "    qr_net_ce = (swdown_toa-swup_toa)+(lwdown_toa-lwup_toa) + (lwup_sfc-lwdown_sfc)+(swup_sfc-swdown_sfc)\n",
    "\n",
    "    return (qr_net_ce, lwup_toa)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr_org = np.zeros((len(t_org),32))*np.nan\n",
    "lwup_org = np.zeros((len(t_org),32))*np.nan\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = len(time_result[n][0])\n",
    "    qr_org[n,:tmp] = time_result[n][0]\n",
    "    lwup_org[n,:tmp] = time_result[n][1]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('QR_CERES_all_5deg_4ds_M2.mat.npy',qr_org)\n",
    "np.save('lwtoa_CERES_all_5deg_4ds_M2.mat.npy',lwup_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    data_sub = subset_MERRA2(MERRA2_dir+'inst2d_SFLX'\n",
    "                        ,time_event[t],lat_event[t],lon_event[t],2,lat_inc=2.5,lon_inc=2.5)\n",
    " \n",
    "    lhf_sm = data_sub.EVAP.resample(time='3H').nearest()   \n",
    "    shf_sm = data_sub.HFLUX.resample(time='3H').nearest()\n",
    "    lon = lhf_sm.lon\n",
    "    lat = lhf_sm.lat\n",
    "    \n",
    "    lhf_org = np.nanmean(lhf_sm,axis=(1,2))*2.5E6\n",
    "    shf_org = np.nanmean(shf_sm,axis=(1,2))\n",
    "\n",
    "    return (lhf_org, shf_org)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhf_org = np.zeros((len(t_org),32))\n",
    "shf_org = np.zeros((len(t_org),32))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = time_result[n][0].shape[0]\n",
    "    lhf_org[n,:tmp] = time_result[n][0]\n",
    "    shf_org[n,:tmp] = time_result[n][1]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('LHF_all_lat_5deg_4ds_M2.mat.npy',lhf_org)\n",
    "np.save('SHF_all_lat_5deg_4ds_M2.mat.npy',shf_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "        \n",
    "#     try:\n",
    "#         ctp_sub = subset_ISCCP_pc(ISCCP_dir,time_event[t],lat_event[t],lon_event[t],days=2\n",
    "#                                         ,lat_inc=2.5,lon_inc=2.5)\n",
    "        \n",
    "#         ctp_org = np.zeros(33)\n",
    "#         for n in range(33):\n",
    "#             tmp = ctp_sub[n,:,:].values.flatten()\n",
    "#             tmp[tmp<0] = np.nan\n",
    "#             ctp_org[n] = np.nanmean(tmp) # mean ctp\n",
    "        \n",
    "#     except:\n",
    "#         ctp_org = np.zeros(33)*np.nan # if not detected, set zero\n",
    "    \n",
    "#     return ctp_org\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "        \n",
    "    try:\n",
    "        ctp_sub = subset_ISCCP_pc(ISCCP_dir,time_event[t],lat_event[t],lon_event[t],days=2\n",
    "                                        ,lat_inc=2.5,lon_inc=2.5)\n",
    "        \n",
    "        ctp_bins = np.linspace(100,900,21)\n",
    "        ctp_dist = np.zeros((33,len(ctp_bins)-1))\n",
    "        for tt in range(33):\n",
    "            ctp_sm = ctp_sub[tt,:,:].values.flatten()\n",
    "            for i in range(len(ctp_bins)-1):\n",
    "                idx = np.where(np.logical_and(ctp_sm>=ctp_bins[i], ctp_sm<ctp_bins[i+1]))[0]\n",
    "                ctp_dist[tt,i] += len(idx)               \n",
    "        \n",
    "    except:\n",
    "        ctp_bins = np.linspace(100,900,21)\n",
    "        ctp_dist = np.zeros((33,len(ctp_bins)-1)) # if not detected, set zero\n",
    "    \n",
    "    return ctp_dist\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctp_dist_org = np.zeros((len(t_org),33,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_str = 60000\n",
    "for n in range(len(time_result)):\n",
    "    tmp = time_result[n].shape[0]\n",
    "    ctp_dist_org[n,:tmp,:] = time_result[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctp_dist_org[60000,16,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('ctp_dist_all_5deg_4ds_M2.mat.npy',ctp_dist_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.1 s, sys: 3.22 s, total: 8.32 s\n",
      "Wall time: 31min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CWV tendency derived from CWV of 2d, 5d, 10d running mean\n",
    "def write_data(t):\n",
    "    try:\n",
    "        cwv_sub = subset_MERRA2(MERRA2_dir+'inst_2d_hourly'\n",
    "                          ,time_event[t],lat_event[t],lon_event[t],days=15,\n",
    "                          lat_inc=2.5,lon_inc=2.5)\n",
    "        cwv_sm = cwv_sub.TQV.resample(time='3H').nearest()\n",
    "        cwv_2drm = running_mean(cwv_sm.mean(axis=(1,2)),16) # 2d-running mean\n",
    "        cwv_5drm = running_mean(cwv_sm.mean(axis=(1,2)),40) # 5d-running mean\n",
    "        cwv_10drm = running_mean(cwv_sm.mean(axis=(1,2)),80) # 10d-running mean\n",
    "\n",
    "        # time derivatives of running mean\n",
    "        cwv_2ddt = 24*np.gradient(cwv_2drm,3)[120-16:120+17]\n",
    "        cwv_5ddt = 24*np.gradient(cwv_5drm,3)[120-16:120+17]\n",
    "        cwv_10ddt = 24*np.gradient(cwv_10drm,3)[120-16:120+17]\n",
    "        \n",
    "        # running mean\n",
    "        cwv_2drm = cwv_2drm[120-16:120+17]\n",
    "        cwv_5drm = cwv_5drm[120-16:120+17]\n",
    "        cwv_10drm = cwv_10drm[120-16:120+17]\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        cwv_2drm = np.nan*np.zeros(33)\n",
    "        cwv_5drm = np.nan*np.zeros(33)\n",
    "        cwv_10drm = np.nan*np.zeros(33)        \n",
    "        \n",
    "        cwv_2ddt = np.nan*np.zeros(33)\n",
    "        cwv_5ddt = np.nan*np.zeros(33)\n",
    "        cwv_10ddt = np.nan*np.zeros(33)\n",
    "\n",
    "    return (cwv_2drm, cwv_5drm, cwv_10drm, cwv_2ddt, cwv_5ddt, cwv_10ddt)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwv_rm = np.zeros((len(t_org),3,33))\n",
    "cwv_dt = np.zeros((len(t_org),3,33))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    cwv_rm[n,0,:] = time_result[n][0]\n",
    "    cwv_rm[n,1,:] = time_result[n][1]\n",
    "    cwv_rm[n,2,:] = time_result[n][2]\n",
    "    cwv_dt[n,0,:] = time_result[n][3]\n",
    "    cwv_dt[n,1,:] = time_result[n][4]\n",
    "    cwv_dt[n,2,:] = time_result[n][5]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('cwv_2510ds_all_5deg_4ds_M2.mat.npy',cwv_rm)\n",
    "np.save('cwv_dt_2510ds_all_5deg_4ds_M2.mat.npy',cwv_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "\n",
    "    cwv_sub = subset_MERRA2(MERRA2_dir+'inst_2d_hourly'\n",
    "                          ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                          lat_inc=2.5,lon_inc=2.5)\n",
    "    cwv_sm = cwv_sub.TQV.resample(time='3H').nearest()\n",
    "    cwv_org = np.nanmean(cwv_sm,axis=(1,2))\n",
    "    \n",
    "    return cwv_org\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwv_org = np.zeros((len(time_result),33))*np.nan\n",
    "\n",
    "for n in range(len(time_result)):\n",
    "    tmp = len(time_result[n])\n",
    "    cwv_org[n,:tmp] = time_result[n]\n",
    "    \n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('cwv_all_5deg_4ds_M2.mat.npy',cwv_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### required for WHOI surface flux data output #######\n",
    "os.chdir('/data/willytsai/WHOI_oaflux/')\n",
    "data = xr.open_dataset('evapr_oaflux_2014_2018.nc')\n",
    "\n",
    "date = []; date_begin = datetime(2014,1,1)\n",
    "for t in range(1826):\n",
    "    tmp = date_begin + t*timedelta(days=1)\n",
    "    date.append(tmp)\n",
    "\n",
    "evap_xr = xr.DataArray(data.evapr.values,coords=[date,data.lat,data.lon],dims=['time','lat','lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    data_sub = subset_WHOI(WHOI_dir, time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                            lat_inc=2.5,lon_inc=2.5)\n",
    "    \n",
    "    evap_org = data_sub.values.mean(axis=(1,2))\n",
    "\n",
    "    return (evap_org)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evap_org = np.zeros((len(t_org),5))*np.nan\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = len(time_result[n])\n",
    "    evap_org[n,:tmp] = time_result[n]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('LHF_WHOI_all_5deg_4ds_M2.mat.npy',evap_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "    \n",
    "#     data_sub = subset_CERES('/data/willytsai/CERES/'\n",
    "#                           ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "#                             lat_inc=2.5,lon_inc=2.5)\n",
    "    \n",
    "#     swup_toa = np.nanmean(data_sub.adj_atmos_sw_up_all_toa_3h,axis=(1,2))\n",
    "#     swup_sfc = np.nanmean(data_sub.adj_atmos_sw_up_all_surface_3h,axis=(1,2))\n",
    "#     swdown_toa = np.nanmean(data_sub.adj_atmos_sw_down_all_toa_3h,axis=(1,2))\n",
    "#     swdown_sfc = np.nanmean(data_sub.adj_atmos_sw_down_all_surface_3h,axis=(1,2))\n",
    "#     lwup_toa = np.nanmean(data_sub.adj_atmos_lw_up_all_toa_3h,axis=(1,2))        \n",
    "#     lwup_sfc = np.nanmean(data_sub.adj_atmos_lw_up_all_surface_3h,axis=(1,2))  \n",
    "#     lwdown_toa = np.nanmean(data_sub.adj_atmos_lw_down_all_toa_3h,axis=(1,2))      \n",
    "#     lwdown_sfc = np.nanmean(data_sub.adj_atmos_lw_down_all_surface_3h,axis=(1,2))  \n",
    "\n",
    "#     # net atmosphere radiation \n",
    "#     qr_net_ce = (swdown_toa-swup_toa)+(lwdown_toa-lwup_toa) + (lwup_sfc-lwdown_sfc)+(swup_sfc-swdown_sfc)\n",
    "\n",
    "#     return (qr_net_ce, lwup_toa)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qr_org = np.zeros((len(t_org),32))*np.nan\n",
    "# lwup_org = np.zeros((len(t_org),32))*np.nan\n",
    "\n",
    "# for n in range(len(t_org)):\n",
    "#     tmp = len(time_result[n][0])\n",
    "#     qr_org[n,:tmp] = time_result[n][0]\n",
    "#     lwup_org[n,:tmp] = time_result[n][1]\n",
    "\n",
    "# os.chdir('/data/willytsai/ISCCP')\n",
    "# np.save('QR_CERES_all_5deg_4ds_M2.mat.npy',qr_org)\n",
    "# np.save('lwtoa_CERES_all_5deg_4ds_M2.mat.npy',lwup_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    data_sub2 = subset_TRMM(TRMM_dir+'2009_2018'\n",
    "                          ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                            lat_inc=2.5,lon_inc=2.5)\n",
    "    \n",
    "    prec_sm = data_sub2.precipitation\n",
    "    prec_bins = np.linspace(0,60,31)\n",
    "    prec_dist = np.zeros((33,len(prec_bins)-1))\n",
    "    \n",
    "    for tt in range(33):\n",
    "        prec_1d = prec_sm[tt,:,:].values.flatten()\n",
    "\n",
    "        for i in range(len(prec_bins)-1):\n",
    "            idx = np.where(np.logical_and(prec_1d>=prec_bins[i],prec_1d<prec_bins[i+1]))[0]\n",
    "            prec_dist[tt,i] += len(idx)\n",
    "\n",
    "#    prec_org = np.nanmean(prec_sm,axis=(1,2))\n",
    "#    prec_trim = running_mean(prec_org,8)\n",
    "#    prec_trim = prec_trim[8:-8]\n",
    "    return (prec_dist)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precdist_org = np.zeros((len(t_org),33,30))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = len(time_result[n])\n",
    "    precdist_org[n,:tmp,:] = time_result[n]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('precdist_all_5deg_4ds_M2.mat.npy',precdist_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t): # gross moist stability\n",
    "    \n",
    "        data_sub = subset_MERRA2(MERRA2_3d_dir\n",
    "                               ,time_event[t],lat_event[t],lon_event[t],days=2,lon_inc=2.5,lat_inc=2.5)\n",
    "#         data_sub2 = subset_MERRA2(MERRA2_3d_dir+'../omega_3hr'\n",
    "#                          ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "#                           lat_inc=2.5,lon_inc=2.5)\n",
    "        data_sub3 = subset_MERRA2(MERRA2_3d_dir+'../geoheight_3hr/'\n",
    "                         ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                          lat_inc=2.5,lon_inc=2.5)\n",
    "        \n",
    "        u_sm = data_sub.U\n",
    "        v_sm = data_sub.V\n",
    "        T_sm = data_sub.T\n",
    "#         omega_sm = data_sub2.OMEGA\n",
    "        q_sm = data_sub.QV\n",
    "        z_sm = data_sub3.H\n",
    "        lev = T_sm.lev\n",
    "        lon = T_sm.lon\n",
    "        lat = T_sm.lat\n",
    "                \n",
    "        h_sm = 1004*T_sm + 2.5e6*q_sm + 9.8*z_sm \n",
    "        s_sm = 1004*T_sm + 9.8*z_sm \n",
    "    \n",
    "#        hadv_sm = u_sm*np.gradient(h_sm,lon*100000,axis=3) + v_sm*np.gradient(h_sm,lat*100000,axis=2)\n",
    "#        sadv_sm = u_sm*np.gradient(s_sm,lon*100000,axis=3) + v_sm*np.gradient(s_sm,lat*100000,axis=2)\n",
    "        \n",
    "        dhdx = np.nanmean(np.gradient(h_sm,lon*100000,axis=3),axis=(2,3))\n",
    "        dhdy = np.nanmean(np.gradient(h_sm,lat*100000,axis=2),axis=(2,3))\n",
    "        hadv_org = u_sm.mean(axis=(2,3))*dhdx + v_sm.mean(axis=(2,3))*dhdy\n",
    "        \n",
    "        dsdx = np.nanmean(np.gradient(s_sm,lon*100000,axis=3),axis=(2,3))\n",
    "        dsdy = np.nanmean(np.gradient(s_sm,lat*100000,axis=2),axis=(2,3))\n",
    "        sadv_org = u_sm.mean(axis=(2,3))*dsdx + v_sm.mean(axis=(2,3))*dsdy\n",
    "    \n",
    "#         hflux_org = np.nanmean(hflux_sm,axis=(2,3))\n",
    "#         sflux_org = np.nanmean(sflux_sm,axis=(2,3))\n",
    "\n",
    "        return (hadv_org, sadv_org)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadv_org = np.zeros((len(t_org),33,42))\n",
    "sadv_org = np.zeros((len(t_org),33,42))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = len(time_result[n][0])\n",
    "    hadv_org[n,:tmp,:] = time_result[n][0]\n",
    "    sadv_org[n,:tmp,:] = time_result[n][1]\n",
    "    \n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('hadv_mn_all_5deg_4ds_M2.mat.npy',hadv_org)\n",
    "np.save('sadv_mn_all_5deg_4ds_M2.mat.npy',sadv_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t): # gross moist stability\n",
    "    \n",
    "        data_sub = subset_MERRA2(MERRA2_3d_dir\n",
    "                               ,time_event[t],lat_event[t],lon_event[t],days=2,lon_inc=2.5,lat_inc=2.5)\n",
    "#         data_sub2 = subset_MERRA2(MERRA2_3d_dir+'../omega_3hr'\n",
    "#                          ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "#                           lat_inc=2.5,lon_inc=2.5)\n",
    "        data_sub3 = subset_MERRA2(MERRA2_3d_dir+'../geoheight_3hr/'\n",
    "                         ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                          lat_inc=2.5,lon_inc=2.5)\n",
    "        \n",
    "#         u_sm = data_sub.U\n",
    "#         v_sm = data_sub.V\n",
    "        T_sm = data_sub.T\n",
    "#         omega_sm = data_sub2.OMEGA\n",
    "        q_sm = data_sub.QV\n",
    "        z_sm = data_sub3.H\n",
    "        lev = T_sm.lev\n",
    "        lon = T_sm.lon\n",
    "        lat = T_sm.lat\n",
    "                \n",
    "        h_sm = 1004*T_sm + 2.5e6*q_sm + 9.8*z_sm \n",
    "        s_sm = 1004*T_sm + 9.8*z_sm \n",
    "    \n",
    "#         hflux_sm = np.gradient(h_sm*u_sm,lon*100000,axis=3) +  \\\n",
    "#                   np.gradient(h_sm*v_sm,lat*100000,axis=2) + np.gradient(h_sm*omega_sm,lev*100,axis=1)\n",
    "#         sflux_sm = np.gradient(s_sm*u_sm,lon*100000,axis=3) +  \\\n",
    "#                   np.gradient(s_sm*v_sm,lat*100000,axis=2) + np.gradient(s_sm*omega_sm,lev*100,axis=1)\n",
    "    \n",
    "#         hflux_org = np.nanmean(hflux_sm,axis=(2,3))\n",
    "#         sflux_org = np.nanmean(sflux_sm,axis=(2,3))\n",
    "        h_org = np.nanmean(h_sm,axis=(2,3))\n",
    "        s_org = np.nanmean(s_sm,axis=(2,3))\n",
    "\n",
    "        return (h_org, s_org)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_org = np.zeros((len(t_org),33,42))\n",
    "h_org = np.zeros((len(t_org),33,42))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = len(time_result[n][0])\n",
    "    h_org[n,:tmp,:] = time_result[n][0]\n",
    "    s_org[n,:tmp,:] = time_result[n][1]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('dse_all_5deg_4ds_M2.mat.npy',s_org)\n",
    "np.save('mse_all_5deg_4ds_M2.mat.npy',h_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t): \n",
    "    \n",
    "        data_sub = subset_MERRA2(MERRA2_3d_dir\n",
    "                               ,time_event[t],lat_event[t],lon_event[t],2,lon_inc=2.5,lat_inc=2.5)\n",
    "        u_sm = data_sub.U\n",
    "        v_sm = data_sub.V\n",
    "        lev = data_sub.lev\n",
    "        \n",
    "        # Alexander and Young (1992), Weisman and Klemp (1982) definition of LLWS \n",
    "        u_950 = u_sm.sel(lev=slice(1000,950)).mean(axis=(2,3))\n",
    "        u_950m = np.trapz(u_950,u_950.lev,axis=1)/(1000-950)\n",
    "        u_500 = u_sm.sel(lev=slice(1000,500)).mean(axis=(2,3))\n",
    "        u_500m = np.trapz(u_500,u_500.lev,axis=1)/(1000-500)\n",
    "\n",
    "        v_950 = v_sm.sel(lev=slice(1000,950)).mean(axis=(2,3))\n",
    "        v_950m = np.trapz(v_950,v_950.lev,axis=1)/(1000-950)\n",
    "        v_500 = v_sm.sel(lev=slice(1000,500)).mean(axis=(2,3))\n",
    "        v_500m = np.trapz(v_500,v_500.lev,axis=1)/(1000-500)\n",
    "\n",
    "        LLS_sm = 1/2 *( (u_500m - u_950m)**2 + (v_500m - v_950m)**2 )\n",
    "        #LLS_sm  = np.nanmean(LLS,axis=(1,2))\n",
    "        \n",
    "        return LLS_sm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLS_org = np.zeros((len(t_org),33))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = len(time_result[n])\n",
    "    LLS_org[n,:tmp] = time_result[n]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('LLWS_all_5deg_4ds_M2.mat.npy',LLS_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "\n",
    "    omega_sub = subset_MERRA2(MERRA2_3d_dir+'../omega_3hr'\n",
    "                         ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                          lat_inc=2.5,lon_inc=2.5)\n",
    "    omega_sm = omega_sub.OMEGA\n",
    "    omega_mn = np.zeros((33,42))\n",
    "    omega_90th = np.copy(omega_mn)\n",
    "    omega_10th = np.copy(omega_mn)\n",
    "\n",
    "    for n in range(33):\n",
    "        # finding omega ranking at each level\n",
    "\n",
    "        omega_re = np.reshape(omega_sm[n,:,:,:].values,(42,omega_sm.shape[2]*omega_sm.shape[3]))\n",
    "        omega_mn[n,:] = np.nanmean(omega_re,axis=1) \n",
    "\n",
    "        omega_tmp = np.nanmean(omega_sm[n,:,:,:],axis=0).ravel()\n",
    "        val_90 = np.percentile(omega_tmp,90)\n",
    "        val_10 = np.percentile(omega_tmp,10)\n",
    "        omega_90th[n,:] = np.nanmean(omega_re[:,np.where(omega_tmp>val_90)[0]],axis=1)\n",
    "        omega_10th[n,:] = np.nanmean(omega_re[:,np.where(omega_tmp<val_10)[0]],axis=1)\n",
    "    \n",
    "    return omega_mn, omega_90th, omega_10th\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_mn_org = np.zeros((len(t_org),33,42))\n",
    "omega_90th_org = np.zeros((len(t_org),33,42))\n",
    "omega_10th_org = np.zeros((len(t_org),33,42))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = len(time_result[n][0])\n",
    "    omega_mn_org[n,:tmp,:] = time_result[n][0]\n",
    "    omega_90th_org[n,:tmp,:] = time_result[n][1]\n",
    "    omega_10th_org[n,:tmp,:] = time_result[n][2]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('omega_all_5deg_4ds_M2.mat.npy',omega_mn_org)\n",
    "np.save('omega_90th_all_5deg_4ds_M2.mat.npy',omega_90th_org)\n",
    "np.save('omega_10th_all_5deg_4ds_M2.mat.npy',omega_10th_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "        data_sub = subset_MERRA2(MERRA2_3d_dir\n",
    "                               ,time_event[t],lat_event[t],lon_event[t],2,lon_inc=2.5,lat_inc=2.5)\n",
    "        u_sm = data_sub.U\n",
    "        v_sm = data_sub.V\n",
    "        lev = u_sm.lev\n",
    "        lon = u_sm.lon\n",
    "        lat = u_sm.lat\n",
    "   \n",
    "        div_sm = np.gradient(u_sm,lon*100000,axis=3) +  \\\n",
    "                  np.gradient(v_sm,lat*100000,axis=2)\n",
    "    \n",
    "        div_org = np.nanmean(div_sm,axis=(2,3))\n",
    "        \n",
    "        return (div_org)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_org = np.zeros((len(time_result),33,42))*np.nan\n",
    "\n",
    "for n in range(len(time_result)):\n",
    "    tmp = len(time_result[n])\n",
    "    div_org[n,:tmp,:] = time_result[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('div_all_5deg_4ds_M2.mat.npy',div_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 1.73 s, total: 2.91 s\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def write_data(t): ## Horizontal cwv gradient \n",
    "\n",
    "    cwv_sub = subset_MERRA2(MERRA2_dir+'inst_2d_hourly'\n",
    "                          ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                          lat_inc=2.5,lon_inc=2.5)\n",
    "    cwv_sm = cwv_sub.TQV.resample(time='3H').nearest()\n",
    "    cwv_xgrad = np.abs(np.gradient(cwv_sm, cwv_sm.lon*100000, axis=2))\n",
    "    cwv_ygrad = np.abs(np.gradient(cwv_sm, cwv_sm.lat*100000, axis=1))\n",
    "\n",
    "    cwv_xmean = np.nanmean(cwv_xgrad,axis=(1,2))\n",
    "    cwv_ymean = np.nanmean(cwv_ygrad,axis=(1,2))\n",
    "\n",
    "    return cwv_xmean, cwv_ymean\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwvx_org = np.zeros((len(time_result),33))*np.nan\n",
    "cwvy_org = np.zeros((len(time_result),33))*np.nan\n",
    "\n",
    "for n in range(len(time_result)):\n",
    "    tmp = len(time_result[n][0])\n",
    "    cwvx_org[n,:tmp] = time_result[n][0]\n",
    "    cwvy_org[n,:tmp] = time_result[n][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('cwv_longrad_all_5deg_4ds_M2.mat.npy',cwvx_org)\n",
    "np.save('cwv_latgrad_all_5deg_4ds_M2.mat.npy',cwvy_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(t): ## Horizontal cwv gradient \n",
    "\n",
    "    data = subset_MERRA2('/data/willytsai/Rad_new_hrly/'\n",
    "                          ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                          lat_inc=2.5,lon_inc=2.5)\n",
    "\n",
    "    lwtoa_sm = data.LWTUP.resample(time='3H').nearest()\n",
    "    swtoa_sm = data.SWTNT.resample(time='3H').nearest()\n",
    "    lwgnt_sm = data.LWGNT.resample(time='3H').nearest()\n",
    "    swgnt_sm = data.SWGNT.resample(time='3H').nearest()\n",
    "    \n",
    "    lwtoa_org = np.nanmean(lwtoa_sm,axis=(1,2))\n",
    "    swtoa_org = np.nanmean(swtoa_sm,axis=(1,2))\n",
    "    lwgnt_org = np.nanmean(lwgnt_sm,axis=(1,2))\n",
    "    swgnt_org = np.nanmean(swgnt_sm,axis=(1,2))\n",
    "\n",
    "    return lwtoa_org, swtoa_org, lwgnt_org, swgnt_org\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lwtoa_org = np.zeros((len(time_result),32))*np.nan\n",
    "swtoa_org = np.zeros((len(time_result),32))*np.nan\n",
    "lwgnt_org = np.zeros((len(time_result),32))*np.nan\n",
    "swgnt_org = np.zeros((len(time_result),32))*np.nan\n",
    "\n",
    "for n in range(len(time_result)):\n",
    "    tmp = len(time_result[n][0])\n",
    "    lwtoa_org[n,:tmp] = time_result[n][0]\n",
    "    swtoa_org[n,:tmp] = time_result[n][1]\n",
    "    lwgnt_org[n,:tmp] = time_result[n][2]\n",
    "    swgnt_org[n,:tmp] = time_result[n][3]\n",
    "    \n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('lwtoa_all_5deg_4ds_M2.mat.npy',lwtoa_org)\n",
    "np.save('swtoa_all_5deg_4ds_M2.mat.npy',swtoa_org)\n",
    "np.save('lwgnt_all_5deg_4ds_M2.mat.npy',lwgnt_org)\n",
    "np.save('swgnt_all_5deg_4ds_M2.mat.npy',swgnt_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "#     data_sub1 = subset_MERRA2(MERRA2_3d_dir\n",
    "#                          ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "#                           lat_inc=2.5,lon_inc=2.5)\n",
    " \n",
    "#     q_sm = data_sub1.QV\n",
    "#     T_sm = data_sub1.T\n",
    "#     # cape and cin\n",
    "#     p = T_sm.lev.values*units('mbar')\n",
    "#     # cape/cin calculation\n",
    "#     cape_sm = np.zeros(len(T_sm.time))\n",
    "#     cin_sm = np.copy(cape_sm)\n",
    "#     for t in range(len(T_sm.time)):\n",
    "#         T_tmp = np.nanmean(T_sm[t,:,:,:],axis=(1,2))\n",
    "#         q_tmp = np.nanmean(q_sm[t,:,:,:],axis=(1,2))\n",
    "#         T = (T_tmp-273.15)*units('degC')\n",
    "#         q = q_tmp*units('kg/kg')\n",
    "#         Td = mpcalc.dewpoint(mpcalc.vapor_pressure(p,q))\n",
    "        \n",
    "#         try:\n",
    "#             Tp = mpcalc.parcel_profile(p,T[0],Td[0]).to('degC')                    \n",
    "#             el_pressure,el_temperature = mpcalc.el(p,T,Td) # equilibrium level\n",
    "#             el_idx = np.argmin(np.abs(p.magnitude - el_pressure.magnitude))                \n",
    "#             ELps = [el_pressure.magnitude] # Initialize an array of EL pressures for detrainment profile\n",
    "#             [CAPE,CIN] = mpcalc.cape_cin(p[:el_idx],T[:el_idx],Td[:el_idx],Tp[:el_idx])\n",
    "#             cape_sm[t] = CAPE.magnitude\n",
    "#             cin_sm[t] = CIN.magnitude\n",
    "#         except:\n",
    "#             cape_sm[t] = np.nan\n",
    "#             cin_sm[t] = np.nan\n",
    "\n",
    "\n",
    "#     return cape_sm, cin_sm\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cape_org = np.zeros((len(time_result),33))*np.nan\n",
    "# cin_org = np.zeros((len(time_result),33))*np.nan\n",
    "\n",
    "# for n in range(len(time_result)):\n",
    "#     tmp = len(time_result[n][0])\n",
    "#     cape_org[n,:tmp] = time_result[n][0]\n",
    "#     cin_org[n,:tmp] = time_result[n][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/data/willytsai/ISCCP')\n",
    "# np.save('cape_all_5deg_4ds_1DRM.mat.npy',cape_org)\n",
    "# np.save('cin_all_5deg_4ds_1DRM.mat.npyy',cin_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "\n",
    "#     bt_sub = subset_gridsat(Gridsat_dir+'2014_2018',time_event[t],lat_event[t],lon_event[t],days=2\n",
    "#                                         ,lat_inc=2.5,lon_inc=2.5)\n",
    "#     bt_sm = bt_sub.irwin_cdr\n",
    "#     SCAI_BT,N_psT = SCAI_index_bt(bt_sm,cri_val=240)\n",
    "#     cldfrac_sm = [len(np.where(bt_sm[n,:,:] < 240)[0])/(len(bt_sm.lat)*len(bt_sm.lon)) for n in range(33)]\n",
    "# #    bt_org = bt_sm.mean(axis=(1,2))\n",
    "    \n",
    "#     return SCAI_BT, N_psT, cldfrac_sm\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCAI_org = np.zeros((len(t_org),33))*np.nan\n",
    "# N_org = np.zeros((len(t_org),33))*np.nan\n",
    "# cldfrac_org = np.zeros((len(t_org),33))*np.nan\n",
    "\n",
    "# for n in range(len(t_org)):\n",
    "#     tmp = len(time_result[n][0])\n",
    "#     SCAI_org[n,:tmp] = time_result[n][0]\n",
    "#     N_org[n,:tmp] = time_result[n][1]\n",
    "#     cldfrac_org[n,:tmp] = time_result[n][2]\n",
    "\n",
    "# os.chdir('/data/willytsai/ISCCP')\n",
    "# np.save('SCAIbt_all_5deg_4ds_1DRM.mat.npy',SCAI_org)\n",
    "# np.save('N_all_5deg_4ds_1DRM.mat.npy',N_org)\n",
    "# np.save('cldfrac_all_5deg_4ds_1DRM.mat.npy',cldfrac_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "\n",
    "# #    bt_sub = subset_gridsat(Gridsat_dir+'2014_2018',time_event[t],lat_event[t],lon_event[t],days=2\n",
    "# #                                        ,lat_inc=2.5,lon_inc=2.5)\n",
    "#     cwv_sub = subset_MERRA2(MERRA2_dir+'inst_2d_hourly'\n",
    "#                           ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "#                           lat_inc=2.5,lon_inc=2.5)\n",
    "# #    bt_sm = bt_sub.irwin_cdr\n",
    "#     cwv_sm = cwv_sub.TQV.resample(time='3H').nearest()\n",
    "# #     cwv_cld = np.zeros(33); cwv_env = np.copy(cwv_cld);\n",
    "\n",
    "# #     for n in range(33):\n",
    "# #         cwv_tmp = cwv_sm[n,:,:]; bt_tmp = bt_sm[n,:,:]; \n",
    "\n",
    "# #         # interploation for cwv into the same grid size as bt\n",
    "# #         x = cwv_tmp.lon; y= cwv_tmp.lat\n",
    "# #         f = interpolate.interp2d(x, y, cwv_tmp, kind='linear')\n",
    "# #         xnew = bt_tmp.lon; ynew = bt_tmp.lat\n",
    "# #         cwv_re = f(xnew,ynew)\n",
    "\n",
    "# #         cwv_cld[n] = np.nanmean(cwv_re[bt_tmp<240])\n",
    "# #         cwv_env[n] = np.nanmean(cwv_re[bt_tmp>240])\n",
    "#     cwv_org = np.nanstd(cwv_sm,axis=(1,2))\n",
    "    \n",
    "#     return cwv_org\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "\n",
    "    omega_sub = subset_MERRA2(MERRA2_3d_dir+'../omega_3hr'\n",
    "                         ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "                          lat_inc=5,lon_inc=5)\n",
    "    omega_sm = omega_sub.OMEGA\n",
    "    omega_mn = np.zeros((33,42))\n",
    "    omega_90th = np.copy(omega_mn)\n",
    "    omega_10th = np.copy(omega_mn)\n",
    "\n",
    "    for n in range(33):\n",
    "        # finding omega ranking at each level\n",
    "\n",
    "        omega_re = np.reshape(omega_sm[n,:,:,:].values,(42,omega_sm.shape[2]*omega_sm.shape[3]))\n",
    "        omega_mn[n,:] = np.nanmean(omega_re,axis=1) \n",
    "\n",
    "        omega_tmp = np.nanmean(omega_sm[n,:,:,:],axis=0).ravel()\n",
    "        val_90 = np.percentile(omega_tmp,90)\n",
    "        val_10 = np.percentile(omega_tmp,10)\n",
    "        omega_90th[n,:] = np.nanmean(omega_re[:,np.where(omega_tmp>val_90)[0]],axis=1)\n",
    "        omega_10th[n,:] = np.nanmean(omega_re[:,np.where(omega_tmp<val_10)[0]],axis=1)\n",
    "    \n",
    "    return omega_mn, omega_90th, omega_10th\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_result[90000][0][16,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_mn_org = np.zeros((len(t_org),33,42))\n",
    "omega_90th_org = np.zeros((len(t_org),33,42))\n",
    "omega_10th_org = np.zeros((len(t_org),33,42))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = len(time_result[n][0])\n",
    "    omega_mn_org[n,:tmp,:] = time_result[n][0]\n",
    "    omega_90th_org[n,:tmp,:] = time_result[n][1]\n",
    "    omega_10th_org[n,:tmp,:] = time_result[n][2]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('omega_mn_all_10deg_4ds.mat.npy',omega_mn_org)\n",
    "np.save('omega_90th_all_10deg_4ds.mat.npy',omega_90th_org)\n",
    "np.save('omega_10th_all_10deg_4ds.mat.npy',omega_10th_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "\n",
    "#     bt_sub = subset_gridsat(Gridsat_dir+'2014_2018',time_event[t],lat_event[t],lon_event[t],days=2\n",
    "#                                         ,lat_inc=2.5,lon_inc=2.5)\n",
    "#     bt_sm = bt_sub.irwin_cdr\n",
    "#     Iorg_BT = Iorg_index_bt(bt_sm)\n",
    "\n",
    "#     return Iorg_BT\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(1000), chunksize=50)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iorg_org = np.zeros((len(t_org),33))\n",
    "\n",
    "# for n in range(len(t_org)):\n",
    "#     tmp = len(time_result[n])\n",
    "#     Iorg_org[n,:tmp] = time_result[n]\n",
    "\n",
    "# os.chdir('/data/willytsai/ISCCP')\n",
    "# np.save('Iorg2_all_5deg_4ds.mat.npy',Iorg_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "#     tmp = center_case(time_event[t],lon_event[t],lat_event[t],cri_r=200,ratio=0.5)\n",
    "    \n",
    "#     return tmp\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_cent_org = np.zeros((len(t_org)))\n",
    "\n",
    "# for n in range(len(t_org)):\n",
    "#     idx_cent_org[n] = time_result[n]\n",
    "    \n",
    "# os.chdir('/data/willytsai/ISCCP')\n",
    "# np.save('idx_center200kmR05_all_5deg_4ds.mat.npy',idx_cent_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_org = np.zeros((len(t_org),33))\n",
    "# cu_org = np.copy(call_org)\n",
    "# dc_org = np.copy(call_org)\n",
    "# st_org = np.copy(call_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    try:\n",
    "        call_sub,cu_sub,st_sub,dc_sub = subset_ISCCP(ISCCP_dir,time_event[t],lat_event[t],lon_event[t],days=2\n",
    "                                        ,lat_inc=2.5,lon_inc=2.5)\n",
    "        call_org = np.nanmean(call_sub,axis=(1,2))\n",
    "        cu_org = np.nanmean(cu_sub,axis=(1,2))\n",
    "        dc_org = np.nanmean(dc_sub,axis=(1,2))\n",
    "        st_org = np.nanmean(st_sub,axis=(1,2))\n",
    "        \n",
    "    except:\n",
    "        call_org = np.zeros(33)*np.nan\n",
    "        cu_org = np.zeros(33)*np.nan\n",
    "        dc_org = np.zeros(33)*np.nan\n",
    "        st_org = np.zeros(33)*np.nan       \n",
    "    \n",
    "    return call_org,cu_org,dc_org,st_org\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(90000,108419), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_str = 90000\n",
    "for n in range(len(time_result)):\n",
    "    tmp = time_result[n][0].shape[0]\n",
    "    call_org[n+t_str,:tmp] = time_result[n][0]\n",
    "    cu_org[n+t_str,:tmp] = time_result[n][1]    \n",
    "    dc_org[n+t_str,:tmp] = time_result[n][2]\n",
    "    st_org[n+t_str,:tmp] = time_result[n][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('cldmat_call_all_5deg_4ds.mat.npy',call_org)\n",
    "np.save('cldamt_cu_all_5deg_4ds.mat.npy',cu_org)\n",
    "np.save('cldamt_dc_all_5deg_4ds.mat.npy',dc_org)\n",
    "np.save('cldamt_st_all_5deg_4ds.mat.npy',st_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "    \n",
    "#     try:\n",
    "#         call_sub,low_sub,mid_sub,high_sub = subset_ISCCP(ISCCP_dir,time_event[t],lat_event[t],lon_event[t],days=3\n",
    "#                                         ,lat_inc=2.5,lon_inc=2.5)\n",
    "#         call_org = np.nanmean(call_sub,axis=(1,2))\n",
    "#         low_org = np.nanmean(low_sub,axis=(1,2))\n",
    "#         mid_org = np.nanmean(mid_sub,axis=(1,2))\n",
    "#         high_org = np.nanmean(high_sub,axis=(1,2))\n",
    "        \n",
    "#     except:\n",
    "#         call_org = np.zeros(49)*np.nan\n",
    "#         low_org = np.zeros(49)*np.nan\n",
    "#         mid_org = np.zeros(49)*np.nan\n",
    "#         high_org = np.zeros(49)*np.nan       \n",
    "    \n",
    "#     return call_org,low_org,mid_org,high_org\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(80000,83464), chunksize=500)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    try:\n",
    "        data_sub7 = subset_MERRA2(MERRA2_3d_dir+'../Preci_3hr'\n",
    "                            ,time_event[t],lat_event[t],lon_event[t],days=3,\n",
    "                            lat_inc=2.5,lon_inc=2.5)\n",
    "    \n",
    "        precM2_sm = data_sub7.PRECTOT.resample(time='3H').nearest()   \n",
    "        precM2_org = np.nanmean(precM2_sm,axis=(1,2))\n",
    "        precM2_orgrm = running_mean(precM2_org,8)\n",
    "        precM2_org = precM2_org[8:-8]\n",
    "        precM2_orgrm = precM2_orgrm[8:-8]\n",
    "    \n",
    "    except:\n",
    "        precM2_org = np.zeros(32)*np.nan\n",
    "        precM2_orgrm = np.zeros(32)*np.nan\n",
    "    \n",
    "    return precM2_org, precM2_orgrm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precM2_org = np.zeros((len(t_org),32))\n",
    "precM2_orgrm = np.copy(precM2_org)\n",
    "for n in range(len(t_org)):\n",
    "    precM2_org[n,:] = time_result[n][0]\n",
    "    precM2_orgrm[n,:] = time_result[n][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('precM2_all_5deg_4ds_1DRM.mat.npy',precM2_org)\n",
    "np.save('precM2rm_all_5deg_4ds_1DRM.mat.npy',precM2_orgrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "#     data_sub1 = subset_MERRA2(MERRA2_3d_dir\n",
    "#                          ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "#                           lat_inc=2.5,lon_inc=2.5)\n",
    "    \n",
    "# #     data_sub2 = subset_TRMM(TRMM_dir+'2014_2018'\n",
    "# #                           ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "# #                             lat_inc=2.5,lon_inc=2.5)\n",
    "# #     data_sub3 = subset_MERRA2(MERRA2_dir+'inst_2d_hourly'\n",
    "# #                           ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "# #                           lat_inc=2.5,lon_inc=2.5)\n",
    "# #    data_sub4 = subset_MERRA2(MERRA2_3d_dir+'omega_3hr'\n",
    "# #                          ,time_event[t],lat_event[t],lon_event[t],days=3,\n",
    "# #                           lat_inc=2.5,lon_inc=2.5)\n",
    "# #    data_sub5 = subset_gridsat(Gridsat_dir+'2014_2018'\n",
    "# #                          ,time_event[t],lat_event[t],lon_event[t],days=3,\n",
    "# #                          lat_inc=2.5,lon_inc=2.5)\n",
    "# #    data_sub6 = subset_MERRA2(MERRA2_3d_dir+'CWVtend_3hr'\n",
    "# #                          ,time_event[t],lat_event[t],lon_event[t],days=3,\n",
    "# #                           lat_inc=2.5,lon_inc=2.5)\n",
    "\n",
    "# #     data_sub7 = subset_MERRA2(MERRA2_3d_dir+'../Preci_3hr'\n",
    "# #                            ,time_event[t],lat_event[t],lon_event[t],days=2,\n",
    "# #                            lat_inc=2.5,lon_inc=2.5)\n",
    "#     q_sm = data_sub1.QV\n",
    "#     T_sm = data_sub1.T\n",
    "#     u_sm = data_sub1.U\n",
    "#     v_sm = data_sub1.V\n",
    "#     div_sm = np.gradient(u_sm,0.625*100*1e3,axis=3)+np.gradient(v_sm,0.5*100*1e3,axis=2) # divergence 3D\n",
    "# #     prec_sm = data_sub2.precipitation\n",
    "# #     cwv_sm = data_sub3.TQV.resample(time='3H').nearest()   \n",
    "# #     precM2_sm = data_sub7.PRECTOT\n",
    "    \n",
    "# #     prec_org = np.nanmean(prec_sm,axis=(1,2))                  \n",
    "# #     cwv_org =  np.nanmean(cwv_sm,axis=(1,2))\n",
    "# #     precM2_org = np.nanmean(precM2_sm,axis=(1,2))\n",
    "                          \n",
    "#     tmp = np.nanmean(T_sm,axis=(2,3))\n",
    "#     tmp2 = np.nanmean(q_sm,axis=(2,3))\n",
    "# #    tmp3 = np.nanmean(np.nanmean(rh_sm,axis=2),axis=2)\n",
    "#     tmp4 = np.nanmean(div_sm,axis=(2,3))\n",
    "\n",
    "#     T_org = tmp\n",
    "#     q_org = tmp2 \n",
    "#     u_org = np.nanmean(u_sm,axis=(2,3))\n",
    "#     v_org =  np.nanmean(v_sm,axis=(2,3))       \n",
    "#     div_org = tmp4\n",
    "    \n",
    "#     return (T_org,q_org,u_org,v_org,div_org)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)),chunksize=500)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_org = np.zeros((len(t_org),33,42))\n",
    "q_org = np.copy(T_org)\n",
    "u_org = np.copy(T_org)\n",
    "v_org = np.copy(T_org)\n",
    "div_org = np.copy(T_org)\n",
    "\n",
    "for n in range(len(time_result)):    \n",
    "    tmp = len(time_result[n][0])\n",
    "    T_org[n,:tmp] = time_result[n][0]\n",
    "    q_org[n,:tmp] = time_result[n][1]\n",
    "    u_org[n,:tmp] = time_result[n][2]\n",
    "    v_org[n,:tmp] = time_result[n][3]\n",
    "    div_org[n,:tmp] = time_result[n][4]\n",
    "    \n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('T_all_5deg_4ds_1DRM.mat.npy',T_org)\n",
    "np.save('q_all_5deg_4ds_1DRM.mat.npy',q_org)\n",
    "np.save('u_all_5deg_4ds_1DRM.mat.npy',u_org)\n",
    "np.save('v_all_5deg_4ds_1DRM.mat.npy',v_org)\n",
    "np.save('div_all_5deg_4ds_1DRM.mat.npy',div_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prec_org = np.zeros((len(t_org),33))\n",
    "# cwv_org = np.copy(prec_org)\n",
    "# precM2_org = np.zeros((len(t_org),96))\n",
    "# for n in range(len(time_result)):\n",
    "#     prec_org[n,:] = time_result[n][0]\n",
    "#     cwv_org[n,:] = time_result[n][1]\n",
    "#     precM2_org[n,:] = time_result[n][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/data/willytsai/ISCCP')\n",
    "# np.save('T_all_5deg_4ds.mat.npy',T_org)\n",
    "# np.save('q_all_5deg_4ds.mat.npy',q_org)\n",
    "# np.save('u_all_5deg_4ds.mat.npy',u_org)\n",
    "# np.save('v_all_5deg_4ds.mat.npy',v_org)\n",
    "# np.save('div_all_5deg_4ds.mat.npy',div_org)\n",
    "\n",
    "# # np.save('prec_all_5deg_4ds.mat.npy',prec_org)\n",
    "# # np.save('cwv_all_5deg_4ds.mat.npy',cwv_org)\n",
    "# # np.save('precM2_all_5deg_4ds.mat.npy',precM2_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "    \n",
    "#         data_sub = subset_MERRA2(MERRA2_3d_dir\n",
    "#                                ,time_event[t],lat_event[t],lon_event[t],3,lon_inc=2.5,lat_inc=2.5)\n",
    "#         u_sm = data_sub.U\n",
    "#         v_sm = data_sub.V\n",
    "#         q_sm = data_sub.QV\n",
    "#         lev = u_sm.lev\n",
    "#         lon = u_sm.lon\n",
    "#         lat = u_sm.lat\n",
    "   \n",
    "#         qvflux_sm = np.gradient(q_sm*u_sm,lon*100000,axis=3) +  \\\n",
    "#                   np.gradient(q_sm*v_sm,lat*100000,axis=2)\n",
    "    \n",
    "#         qvflux_org = np.nanmean(qvflux_sm,axis=(2,3))\n",
    "        \n",
    "#         return (qvflux_org)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)), chunksize=50)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "\n",
    "    rh_sub = subset_MERRA2('/data/willytsai/RH_3hr_p',time_event[t],lat_event[t],lon_event[t],days=2\n",
    "                                        ,lat_inc=2.5,lon_inc=2.5)\n",
    "    rh_sm = rh_sub.RH.values\n",
    "    rh = np.nanmean(rh_sm,axis=(2,3))\n",
    "    \n",
    "    return (rh)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=50)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_org = np.zeros((len(t_org),33,42))*np.nan\n",
    "for n in range(len(t_org)):\n",
    "    tmp = time_result[n].shape[0]\n",
    "    rh_org[n,:tmp,:] = time_result[n]\n",
    "    \n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('rh_all_5deg_4ds_1DRM.mat.npy',rh_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    data_sub = subset_MERRA2(MERRA2_3d_dir\n",
    "                        ,time_event[t],lat_event[t],lon_event[t],2,lat_inc=2.5,lon_inc=2.5)\n",
    "    T_sm = data_sub.T\n",
    "    q_sm = data_sub.QV\n",
    "    lev = T_sm.lev\n",
    "    es = 6.1094*np.exp(17.625*(T_sm-273)/(T_sm-273+243.04))\n",
    "    p = (q_sm/q_sm)*lev\n",
    "    qs = es/(p-es)*0.622\n",
    "    crh_sm = np.trapz(q_sm[:,:25,:,:],lev[:25],axis=1)/np.trapz(qs[:,:25,:,:],lev[:25],axis=1) # mass-weighted CRH, <CRH>\n",
    "\n",
    "    crh_org = np.nanmean(crh_sm,axis=(1,2))       \n",
    "    return (crh_org)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crh_org = np.zeros((len(t_org),33))*np.nan\n",
    "for n in range(len(t_org)):\n",
    "    tmp = time_result[n].shape[0]\n",
    "    crh_org[n,:tmp] = time_result[n]\n",
    "    \n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('crh_all_lat_5deg_4ds_1DRM.mat.npy',crh_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    data_sub = subset_MERRA2('/data/willytsai/omega_3hr/'\n",
    "                        ,time_event[t],lat_event[t],lon_event[t],2,lat_inc=2.5,lon_inc=2.5)\n",
    " \n",
    "    omega_sm = data_sub.OMEGA\n",
    "    lev = omega_sm.lev\n",
    "    lon = omega_sm.lon\n",
    "    lat = omega_sm.lat\n",
    "    \n",
    "    omega_org = np.nanmean(omega_sm,axis=(2,3))\n",
    "\n",
    "    return (omega_org)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_org = np.zeros((len(t_org),33,42))*np.nan\n",
    "for n in range(len(t_org)):\n",
    "    tmp = time_result[n].shape[0]\n",
    "    omega_org[n,:tmp,:] = time_result[n]\n",
    "    \n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('omega_all_lat_5deg_4ds_1DRM.mat.npy',omega_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    data_sub = subset_MERRA2(MERRA2_3d_dir\n",
    "                        ,time_event[t],lat_event[t],lon_event[t],2,lat_inc=5,lon_inc=7.5)\n",
    " \n",
    "    u_sm = data_sub.U\n",
    "    lev = u_sm.lev\n",
    "    lon = u_sm.lon\n",
    "    lat = u_sm.lat\n",
    "    \n",
    "    u_org = np.nanmean(u_sm,axis=(2))\n",
    "\n",
    "    return (u_org)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=50)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "    \n",
    "#     data_sub = subset_MERRA2(MERRA2_dir+'inst_2d_hourly'\n",
    "#                         ,time_event[t],lat_event[t],lon_event[t],2,lat_inc=7.5,lon_inc=7.5)\n",
    " \n",
    "#     cwv_sm = data_sub.TQV.resample(time='3H').nearest()   \n",
    "#     lon = cwv_sm.lon\n",
    "#     lat = cwv_sm.lat\n",
    "    \n",
    "#     cwv_org = np.nanmean(cwv_sm,axis=(2))\n",
    "\n",
    "#     return (cwv_org)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_org = np.zeros((len(t_org),33,42,31))*np.nan\n",
    "for n in range(len(t_org)):\n",
    "    tmp = time_result[n].shape[0]\n",
    "    tmp2 = time_result[n].shape[1]\n",
    "    u_org[n,:tmp,:tmp2] = time_result[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('cwv_crosssect_all_lat_5deg_4ds.mat.npy',cwv_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "    \n",
    "    data_sub = subset_MERRA2(MERRA2_dir+'inst2d_SFLX'\n",
    "                        ,time_event[t],lat_event[t],lon_event[t],2,lat_inc=2.5,lon_inc=2.5)\n",
    " \n",
    "    lhf_sm = data_sub.EVAP.resample(time='3H').nearest()   \n",
    "    shf_sm = data_sub.HFLUX.resample(time='3H').nearest()\n",
    "    lon = lhf_sm.lon\n",
    "    lat = lhf_sm.lat\n",
    "    \n",
    "    lhf_org = np.nanmean(lhf_sm,axis=(1,2))*2.5E6\n",
    "    shf_org = np.nanmean(shf_sm,axis=(1,2))\n",
    "\n",
    "    return (lhf_org, shf_org)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhf_org = np.zeros((len(t_org),32))\n",
    "shf_org = np.zeros((len(t_org),32))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    tmp = time_result[n][0].shape[0]\n",
    "    lhf_org[n,:tmp] = time_result[n][0]\n",
    "    shf_org[n,:tmp] = time_result[n][1]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('LHF_all_lat_5deg_4ds_1DRM.mat.npy',lhf_org)\n",
    "np.save('SHF_all_lat_5deg_4ds_1DRM.mat.npy',shf_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/data/willytsai/ISCCP')\n",
    "# np.save('qvflux_crosssect_all_uv_5deg_4ds.mat.npy',qvflux_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prec_org = np.zeros((len(t_org),48))\n",
    "# for n in range(len(t_org)):\n",
    "#     prec_org[n,:] = time_result[n]\n",
    "\n",
    "# os.chdir('/data/willytsai/ISCCP')\n",
    "# np.save('precM2_all_5deg.mat.npy',prec_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "    \n",
    "#         data_sub = subset_MERRA2('/data/willytsai/CWVtend_3hr'\n",
    "#                                ,time_event[t],lat_event[t],lon_event[t],2,lon_inc=2.5,lat_inc=2.5)\n",
    "#         qdyn_sm = data_sub.DQVDT_DYN\n",
    "#         qphy_sm = data_sub.DQVDT_PHY\n",
    "#         qana_sm = data_sub.DQVDT_ANA\n",
    "\n",
    "#         qdyn_org = qdyn_sm.mean(axis=(1,2)).values\n",
    "#         qphy_org = qphy_sm.mean(axis=(1,2)).values\n",
    "#         qana_org = qana_sm.mean(axis=(1,2)).values\n",
    "        \n",
    "#         data_sub2 = subset_MERRA2(MERRA2_dir+'inst_2d_hourly'\n",
    "#                                ,time_event[t],lat_event[t],lon_event[t],2,lon_inc=2.5,lat_inc=2.5)\n",
    "#         cwv_sm = data_sub2.TQV\n",
    "#         cwv_org = cwv_sm.mean(axis=(1,2)).values\n",
    "#         cwv_tend = cwv_org[1:]-cwv_org[:-1] # tendency in budget equations\n",
    "                                \n",
    "#         return (cwv_tend, qdyn_org, qphy_org, qana_org)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)), chunksize=50)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "\n",
    "#     bt_sub = subset_gridsat(Gridsat_dir+'2014_2018',time_event[t],lat_event[t],lon_event[t],days=2\n",
    "#                                         ,lat_inc=2.5,lon_inc=2.5)\n",
    "#     bt_sm = bt_sub.irwin_cdr\n",
    "    \n",
    "#     bins = np.linspace(0,500,21) # cloud scale [km]\n",
    "#     cldscale_dist = np.zeros((33,len(bins)-1))\n",
    "#     N_org = np.zeros(33)\n",
    "    \n",
    "#     for tt in range(33):\n",
    "#         label_obj, N = scai.labeled_obj(bt_sm[tt,:,:].values,cri=240,flag=2) # less than 240 K\n",
    "#         size_array = []\n",
    "#         for num in range(1,N+1):\n",
    "#             idx,idy = np.where(label_obj == num)\n",
    "#             size_array.append(len(idx)*10*10) # km^2\n",
    "#         size_array = np.sqrt(np.asarray(size_array)) # cloud scale [km] = sqrt of area\n",
    "    \n",
    "#         # cloud size distribution    \n",
    "#         for i in range(len(bins)-1):\n",
    "#             idd = np.where(np.logical_and(size_array >= bins[i], size_array < bins[i+1]))[0]\n",
    "#             cldscale_dist[tt,i] = len(idd)\n",
    "    \n",
    "#         N_org[tt] = N\n",
    "        \n",
    "#     return cldscale_dist, N_org\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(1000), chunksize=50)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bt_sub = subset_gridsat(Gridsat_dir+'2014_2018',time_event[t],lat_event[t],lon_event[t],days=2\n",
    "#                                         ,lat_inc=2.5,lon_inc=2.5)\n",
    "# bt_sm = bt_sub.irwin_cdr\n",
    "    \n",
    "# bins = np.linspace(0,500,21) # cloud scale [km]\n",
    "# cldscale_dist = np.zeros((33,len(bins)-1))\n",
    "# N_org = np.zeros(33)\n",
    "    \n",
    "# for tt in range(33):\n",
    "#     label_obj, N = scai.labeled_obj(bt_sm[tt,:,:].values,cri=240,flag=2) # less than 240 K\n",
    "#     size_array = []\n",
    "#     for num in range(1,N+1):\n",
    "#         idx,idy = np.where(label_obj == num)\n",
    "#         size_array.append(len(idx)*10*10) # km^2\n",
    "#     size_array = np.sqrt(np.asarray(size_array)) # cloud scale [km] = sqrt of area\n",
    "    \n",
    "#     # cloud size distribution    \n",
    "#     for i in range(len(bins)-1):\n",
    "#         idd = np.where(np.logical_and(size_array >= bins[i], size_array < bins[i+1]))[0]\n",
    "#         cldscale_dist[tt,i] = len(idd)\n",
    "    \n",
    "#     N_org[tt] = N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cldfrac_all[362,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/willytsai/ISCCP')\n",
    "cldfrac_all = np.load('cldfrac_all_5deg_4ds.mat.npy') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cldscale_org = np.zeros((len(t_org),33,20))\n",
    "                                   \n",
    "for n in range(len(t_org)):\n",
    "    cldscale_org[n,:,:] = time_result[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('cldscale_dist_all_5deg_4ds.mat.npy',cldscale_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cwvtend_org = np.zeros((len(t_org),96))\n",
    "# dyn_org = np.copy(cwvtend_org)\n",
    "# phy_org = np.copy(cwvtend_org)\n",
    "# ana_org = np.copy(cwvtend_org)\n",
    "                                   \n",
    "# for n in range(len(t_org)):\n",
    "#     cwvtend_org[n,:] = time_result[n][0]\n",
    "#     dyn_org[n,:] = time_result[n][1]\n",
    "#     phy_org[n,:] = time_result[n][2]\n",
    "#     ana_org[n,:] = time_result[n][3]                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/data/willytsai/ISCCP')\n",
    "# # np.save('cldscale_dist_all_5deg.mat.npy',cldscale_dist_org)\n",
    "# np.save('cwvten_ten_all_5deg_4ds.mat.npy',cwvtend_org)\n",
    "# np.save('cwvten_dyn_all_5deg_4ds.mat.npy',dyn_org)\n",
    "# np.save('cwvten_phy_all_5deg_4ds.mat.npy',phy_org)\n",
    "# np.save('cwvten_ana_all_5deg_4ds.mat.npy',ana_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.3 s, sys: 49.1 s, total: 1min 14s\n",
      "Wall time: 41min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "\n",
    "    bt_sub = subset_gridsat(Gridsat_dir+'2009_2018',time_event[t],lat_event[t],lon_event[t],days=2\n",
    "                                        ,lat_inc=2.5,lon_inc=2.5)\n",
    "    bt_sm = bt_sub.irwin_cdr\n",
    "    \n",
    "    bt_bins = np.linspace(180,300,31)\n",
    "    bt_dist = np.zeros((33,len(bt_bins)-1))\n",
    "    \n",
    "    for tt in range(33):\n",
    "        bt_1d = bt_sm[tt,:,:].values.flatten()\n",
    "\n",
    "        for i in range(len(bt_bins)-1):\n",
    "            idx = np.where(np.logical_and(bt_1d>=bt_bins[i],bt_1d<bt_bins[i+1]))[0]\n",
    "            bt_dist[tt,i] += len(idx)\n",
    "    \n",
    "    return bt_dist\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_dist_org = np.zeros((len(t_org),33,30))\n",
    "                                   \n",
    "for n in range(len(t_org)):\n",
    "    bt_dist_org[n,:,:] = time_result[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('bt_dist_all_5deg_4ds_M2.mat.npy',bt_dist_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cloud regime effective radius "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omegabg(time_cent,lat_cent,lon_cent):\n",
    "    yr = time_cent.year\n",
    "    mn = time_cent.month\n",
    "    os.chdir('/data/willytsai/omega_3hr_monthly/')\n",
    "    if mn < 10:\n",
    "        file = glob('*'+str(yr)+'0'+str(mn)+'*')\n",
    "    else:\n",
    "        file = glob('*'+str(yr)+str(mn)+'*')\n",
    "    data = xr.open_dataset(file[0])\n",
    "    omega_bg = data.OMEGA.sel(lat=slice(lat_cent-7.5,lat_cent+7.5),\n",
    "                             lon=slice(lon_cent-7.5,lon_cent+7.5))\n",
    "    return omega_bg.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "    \n",
    "#     data_sub = subset_MERRA2('/data/willytsai/omega_3hr'\n",
    "#                         ,time_event[t],lat_event[t],lon_event[t],3,lat_inc=7.5,lon_inc=7.5)\n",
    " \n",
    "#     omega_sm = data_sub.OMEGA\n",
    "#     lev = omega_sm.lev\n",
    "#     lon = omega_sm.lon\n",
    "#     lat = omega_sm.lat\n",
    "      \n",
    "#     lat_cent = lat_event[t]; lon_cent = lon_event[t]\n",
    "#     dist_cri = np.linspace(0,750,21)\n",
    "#     lat = omega_sm.lat; lon = omega_sm.lon\n",
    "#     omega_rad = np.zeros((omega_sm.shape[0],len(dist_cri)-1,omega_sm.shape[1]))\n",
    "    \n",
    "#     # get time for removing large-scale background omega (first and last 12h)\n",
    "#     #omega_bg = 0.5*(omega_sm[:12,:,:,:].mean(axis=0)+omega_sm[-12:,:,:,:].mean(axis=0))\n",
    "#     #omega_bg = get_omegabg(time_event[t],lat_cent,lon_cent)\n",
    "    \n",
    "#     # calculate the distance matrix\n",
    "#     for n in range(49):\n",
    "#         x,y = np.meshgrid(lon, lat)\n",
    "#         dist = np.sqrt((x-lon_cent)**2+(y-lat_cent)**2)*100 # distance from center [km]\n",
    "\n",
    "#         for i in range(len(dist_cri)-1):\n",
    "#             idx,idy = np.where(np.logical_and(dist >= dist_cri[i], dist < dist_cri[i+1]))\n",
    "#             omega_rad[n,i,:] = np.nanmean(omega_sm[n,:,idx,idy].values-omega_bg[:,idx,idy],axis=(1,2))\n",
    "\n",
    "#     return omega_rad\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)), chunksize=5)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #qadv_cross_org =  np.zeros((len(t_org),49,42,31))\n",
    "# #qvflux_cross_org = np.zeros((len(t_org),49,42,31))\n",
    "# #div_cross_org = np.zeros((len(t_org),49,42,31))\n",
    "# v_cross_org =  np.zeros((len(t_org),49,42,31))\n",
    "\n",
    "# for n in range(len(t_org)):\n",
    "#     tmp = time_result[n][0].shape[2]\n",
    "#     v_cross_org[n,:,:,:tmp] = time_result[n]\n",
    "#     #qadv_cross_org[n,:,:,:tmp] = time_result[n][0]\n",
    "#     #div_cross_org[n,:,:,:tmp] = time_result[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/data/willytsai/ISCCP')\n",
    "# np.save('qvflux_crosssect_all_vonly_5deg.mat.npy',qvflux_cross_org)\n",
    "# #np.save('qadv_crosssect_all_vonly_5deg.mat.npy',qadv_cross_org)\n",
    "# #np.save('div_crosssect_all_5deg.mat.npy',div_cross_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "        \n",
    "    try:\n",
    "        ctp_sub = subset_ISCCP_pc(ISCCP_dir,time_event[t],lat_event[t],lon_event[t],days=2\n",
    "                                        ,lat_inc=2.5,lon_inc=2.5)\n",
    "        \n",
    "        ctp_org = np.zeros(33)\n",
    "        for n in range(33):\n",
    "            tmp = ctp_sub[n,:,:].values.flatten()\n",
    "            tmp[tmp<0] = np.nan\n",
    "            ctp_org[n] = np.nanmean(tmp) # mean ctp\n",
    "        \n",
    "    except:\n",
    "        ctp_org = np.zeros(33)*np.nan # if not detected, set zero\n",
    "    \n",
    "    return ctp_org\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(90000,108419), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ctp_org = np.zeros((len(t_org),33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_str = 90000\n",
    "for n in range(len(time_result)):\n",
    "    tmp = time_result[n].shape[0]\n",
    "    ctp_org[n+t_str,:tmp] = time_result[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('ctp_all_5deg_4ds.mat.npy',ctp_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "        \n",
    "    try:\n",
    "        ctp_sub = subset_ISCCP_pc(ISCCP_dir,time_event[t],lat_event[t],lon_event[t],days=2\n",
    "                                        ,lat_inc=2.5,lon_inc=2.5)\n",
    "        \n",
    "        ctp_bins = np.linspace(100,900,21)\n",
    "        ctp_dist = np.zeros((33,len(ctp_bins)-1))\n",
    "        for tt in range(33):\n",
    "            ctp_sm = ctp_sub[tt,:,:].values.flatten()\n",
    "            for i in range(len(ctp_bins)-1):\n",
    "                idx = np.where(np.logical_and(ctp_sm>=ctp_bins[i], ctp_sm<ctp_bins[i+1]))[0]\n",
    "                ctp_dist[tt,i] += len(idx)               \n",
    "        \n",
    "    except:\n",
    "        ctp_bins = np.linspace(100,900,21)\n",
    "        ctp_dist = np.zeros((33,len(ctp_bins)-1)) # if not detected, set zero\n",
    "    \n",
    "    return ctp_dist\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(90000,108419), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ctp_org = np.zeros((len(t_org),33,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_str = 90000\n",
    "for n in range(len(time_result)):\n",
    "    tmp = time_result[n].shape[0]\n",
    "    ctp_org[n+t_str,:tmp,:] = time_result[n]\n",
    "\n",
    "os.chdir('/data/willytsai/ISCCP')\n",
    "np.save('ctp_dist_all_5deg_4ds.mat.npy',ctp_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# def write_data(t):\n",
    "\n",
    "#     rh_sub = subset_MERRA2('/data/willytsai/RH_3hr_p',time_event[t],lat_event[t],lon_event[t],days=3\n",
    "#                                         ,lat_inc=2.5,lon_inc=2.5)\n",
    "#     rh_sm = rh_sub.RH.values\n",
    "#     rh = np.nanmean(rh_sm,axis=(2,3))\n",
    "    \n",
    "#     data_sub = subset_MERRA2(MERRA2_dir+'inst_2d_hourly'\n",
    "#                                ,time_event[t],lat_event[t],lon_event[t],3,lon_inc=2.5,lat_inc=2.5)\n",
    "#     cwv_sm = data_sub.TQV.resample(time='3H').nearest().values\n",
    "    \n",
    "#     cwv_1d = cwv_sm.reshape(cwv_sm.shape[0],cwv_sm.shape[1]*cwv_sm.shape[2])\n",
    "#     rh_1d = rh_sm.reshape(rh_sm.shape[0],rh_sm.shape[1],rh_sm.shape[2]*rh_sm.shape[3])\n",
    "#     idx_sort = np.argsort(cwv_1d,axis=1)\n",
    "      \n",
    "#     rh_q1 = np.nanmean(rh_1d[:,:,:int(cwv_1d.shape[1]/4)],axis=2) # 1st quatile\n",
    "#     rh_q4 = np.nanmean(rh_1d[:,:,-int(cwv_1d.shape[1]/4):],axis=2) # 4th quatile\n",
    "        \n",
    "#     return(rh, rh_q1, rh_q4)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     pool = Pool()\n",
    "#     time_result = pool.map(write_data, range(len(t_org)), chunksize=5)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rst = 60000\n",
    "# for n in range(len(time_result)):\n",
    "#     if len(time_result[n]) == 49:\n",
    "#         ctp_org[n+rst,:] = time_result[n]\n",
    "#     else:\n",
    "#         ctp_org[n+rst,:] = np.nan*np.zeros(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def write_data(t):\n",
    "\n",
    "    bt_sub = subset_gridsat(Gridsat_dir+'2014_2018',time_event[t],lat_event[t],lon_event[t],days=2\n",
    "                                        ,lat_inc=2.5,lon_inc=2.5)\n",
    "    bt_sm = bt_sub.irwin_cdr\n",
    "    SCAI_BT,N_psT = SCAI_index_bt(bt_sm,cri_val=208)\n",
    "#    cldfrac_sm = [len(np.where(bt_sm[n,:,:] < 240)[0])/(len(bt_sm.lat)*len(bt_sm.lon)) for n in range(33)]\n",
    "#    bt_org = bt_sm.mean(axis=(1,2))\n",
    "    \n",
    "    return SCAI_BT\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    pool = Pool()\n",
    "    time_result = pool.map(write_data, range(len(t_org)), chunksize=500)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_org = np.zeros((len(t_org),33))\n",
    "\n",
    "for n in range(len(t_org)):\n",
    "    bt_org[n,:] = time_result[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('bt_all_5deg_4ds.mat.npy',bt_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCAI_bt = np.zeros((len(t_org),33))\n",
    "# N_bt = np.copy(SCAI_bt)\n",
    "# cldfrac = np.copy(SCAI_bt)\n",
    "\n",
    "# for n in range(len(t_org)):\n",
    "#     SCAI_bt[n,:] = time_result[n][0]\n",
    "#     N_bt[n,:] = time_result[n][1]\n",
    "#     cldfrac[n,:] = time_result[n][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# os.chdir('/data/willytsai/ISCCP')\n",
    "# np.save('cwv_crosssect_all_5deg.mat.npy',cwv_radius_org)\n",
    "#np.save('ctpir_all_5deg.mat.npy',ctp_org)\n",
    "# np.save('rh_all_5deg.mat.npy',rh_org)\n",
    "# np.save('rh_q1_all_5deg.mat.npy',rh_q1_org)\n",
    "# # np.save('rh_q4_all_5deg.mat.npy',rh_q4_org)\n",
    "# np.save('SCAIbt_all_5deg_4ds.mat.npy',SCAI_bt)\n",
    "# np.save('N_all_5deg_4ds.mat.npy',N_bt)\n",
    "# np.save('cldfrac_all_5deg_4ds.mat.npy',cldfrac)\n",
    "#np.save('crh_q1_all_5deg.mat.npy',crh_q1_org)\n",
    "#np.save('crh_q4_all_5deg.mat.npy',crh_q4_org)\n",
    "#np.save('qvfluxm_all_5deg.mat.npy',qvfluxm_org)\n",
    "#np.save('cwv_q1_all_5deg.mat.npy',cwv_q1_org)\n",
    "#np.save('cwv_q4_all_5deg.mat.npy',cwv_q4_org)\n",
    "#np.save('buoy_all_5deg.mat.npy',buoy_org)\n",
    "# np.save('T_pblstd_all.mat.npy',T_pblstd_org)\n",
    "# np.save('q_pblstd_all.mat.npy',q_pblstd_org)\n",
    "#np.save('cldamt_cu_all_5deg.mat.npy',cldamt_cu_org);#np.save('qverta_scat.mat.npy',qverta_scat)\n",
    "#np.save('cldamt_st_all_5deg.mat.npy',cldamt_st_org);#np.save('qverta_scat.mat.npy',qverta_scat)\n",
    "#np.save('cldamt_dc_all_5deg.mat.npy',cldamt_dc_org);#np.save('qverta_scat.mat.npy',qverta_scat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### load cases org and scat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cldamt_cu_all = np.load('cldamt_cu_all.mat.npy')\n",
    "cldamt_st_all = np.load('cldamt_st_all.mat.npy')\n",
    "cldamt_dc_all = np.load('cldamt_dc_all.mat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cldamt_cu_all[0,:],'k')\n",
    "plt.plot(cldamt_st_all[0,:],'r')\n",
    "plt.plot(cldamt_dc_all[0,:],'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/w2-data/willytsai/ISCCP')\n",
    "# T_all = np.load('T_all.mat.npy')\n",
    "# u_all = np.load('u_all.mat.npy')\n",
    "# v_all = np.load('v_all.mat.npy')\n",
    "# q_all = np.load('q_all.mat.npy')\n",
    "# N_all = np.load('N_all.mat.npy')\n",
    "# SCAIbt_all = np.load('SCAIbt_all.mat.npy')\n",
    "# bt_all = np.load('bt_all.mat.npy')\n",
    "# llws_all = np.load('llws_all.mat.npy')\n",
    "# prec_all = np.load('prec_all.mat.npy')\n",
    "# precstd_all = np.load('precstd_all.mat.npy')\n",
    "# cwv_all = np.load('cwv_all.mat.npy')\n",
    "# crh_all = np.load('crh_all.mat.npy')\n",
    "# # dcamt_all = np.load('dcamt_all.mat.npy')\n",
    "# # cuamt_all = np.load('cuamt_all.mat.npy')\n",
    "# # stamt_all = np.load('stamt_all.mat.npy')\n",
    "# omega_all = np.load('omega_all.mat.npy')\n",
    "# rh_all = np.load('rh_all.mat.npy')\n",
    "# cwvstd_all = np.load('cwvstd_all.mat.npy')\n",
    "# SF_all = np.load('SF_all.mat.npy')\n",
    "# cldfrac_all = np.load('cldfrac_all.mat.npy')\n",
    "# CFv_all = np.load('CFv_all.mat.npy')\n",
    "# div_all  = np.load('div_all.mat.npy')\n",
    "# cwvten_dyn_all = np.load('cwvten_dyn_all.mat.npy')\n",
    "# cwvten_phy_all = np.load('cwvten_phy_all.mat.npy')\n",
    "# cwvten_ana_all = np.load('cwvten_ana_all.mat.npy')\n",
    "# cwvten_tot_all = cwvten_dyn_all+cwvten_phy_all+cwvten_ana_all\n",
    "# Abar_all = cldfrac_all/N_all*1600\n",
    "# cape_all = np.load('cape_all.mat.npy')\n",
    "# cin_all = np.load('cin_all.mat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
