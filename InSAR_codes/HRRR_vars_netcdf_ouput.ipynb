{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess HRRR variable into merged netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cfgrib\n",
    "import cf2cdm\n",
    "from glob import glob\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import urllib.request\n",
    "from cfgrib.xarray_store import open_dataset\n",
    "import warnings\n",
    "import h5py\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37.228, 43.223568, -119.00549, -114.65358]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get geolocation from InSAR\n",
    "geo_file = '/data2/willytsai/InSAR_HRRR/CentralNevadaSenAT166/mintpy/inputs/geometryRadar.h5'\n",
    "geo = h5py.File(geo_file,'r')\n",
    "# for key in geo.keys():\n",
    "#     print(key) #Names of the groups in HDF5 file.\n",
    "lat = geo['latitude'];\n",
    "lon = geo['longitude'];\n",
    "incidence = geo['incidenceAngle'];\n",
    "axis_bound = [np.min(lat),np.max(lat),np.min(lon),np.max(lon)]; # coordinate bound [South,North,West,East]\n",
    "axis_bound = [np.unique(lat.value)[1],np.unique(lat.value)[-1],np.unique(lon.value)[0],np.unique(lon.value)[-2]]\n",
    "axis_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data2/willytsai/InSAR_HRRR/HRRR_data/google_archive/regrid_3km/')\n",
    "files = sorted(glob('*grib2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR file: hrrr.20150322.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20150403.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20150415.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20150509.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20150626.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20150720.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20150906.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20160104.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20160221.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20160316.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20160409.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20160503.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20160527.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20160714.t02z.regrid3km.grib2\n",
      "ERROR file: hrrr.20160807.t02z.regrid3km.grib2\n"
     ]
    }
   ],
   "source": [
    "# merge HRRR dataset \n",
    "tmp = xr.open_dataset('hrrr.20171007.t02z.regrid3km.grib2',engine='cfgrib',\n",
    "                            backend_kwargs=dict(filter_by_keys={'typeOfLevel':'unknown'}))\n",
    "pwat_tmp = tmp.pwat.sel(latitude=slice(axis_bound[0],axis_bound[1]),longitude=slice(axis_bound[2]+360,axis_bound[3]+360))\n",
    "\n",
    "pwat_acqu = np.zeros((len(files),pwat_tmp.shape[0],pwat_tmp.shape[1]))\n",
    "date_frame = []\n",
    "\n",
    "for t in range(len(files)):\n",
    "    \n",
    "    date_frame.append(datetime.strptime(files[t][5:18],'%Y%m%d.t%Hz'))\n",
    "    try:\n",
    "        ds = xr.open_dataset(files[t],engine='cfgrib',\n",
    "                            backend_kwargs=dict(filter_by_keys={'typeOfLevel':'unknown'}))\n",
    "        pwat = ds.pwat.sel(latitude=slice(axis_bound[0],axis_bound[1]),longitude=slice(axis_bound[2]+360,axis_bound[3]+360))\n",
    "        pwat_acqu[t,:,:] = pwat.values   \n",
    "    except:\n",
    "        print('ERROR file: '+files[t])\n",
    "        pwat_acqu[t,:,:] = np.nan\n",
    "\n",
    "# convert into xarray \n",
    "pwat_acqu_xr = xr.DataArray(pwat_acqu,dims=('time','latitude','longitude')\n",
    "                            ,coords=(date_frame,pwat.latitude,pwat.longitude-360),name='pwat')\n",
    "#pwat_acqu_xr.to_netcdf('/data2/willytsai/InSAR_HRRR/HRRR_data/t02z/merged/HRRR_pwat_NEVADA.nc')\n",
    "pwat_ds = pwat_acqu_xr.to_dataset(name='pwat')\n",
    "pwat_ds.to_netcdf('/data2/willytsai/InSAR_HRRR/HRRR_data/google_archive/regrid_3km/HRRR_pwat_NEVADA.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = xr.open_dataset('hrrr.20171007.t02z.regrid3km.grib2',engine='cfgrib',\n",
    "                            backend_kwargs=dict(filter_by_keys={'stepType': 'instant', 'typeOfLevel': 'surface'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_tmp = tmp.sp.sel(latitude=slice(axis_bound[0],axis_bound[1]),longitude=slice(axis_bound[2]+360,axis_bound[3]+360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge HRRR dataset \n",
    "tmp = xr.open_dataset('hrrr.20171007.t02z.regrid3km.grib2',engine='cfgrib',\n",
    "                            backend_kwargs=dict(filter_by_keys={'stepType': 'instant', 'typeOfLevel': 'surface'}))\n",
    "ps_tmp = tmp.sp.sel(latitude=slice(axis_bound[0],axis_bound[1]),longitude=slice(axis_bound[2]+360,axis_bound[3]+360))\n",
    "\n",
    "ps_acqu = np.zeros((len(files),ps_tmp.shape[0],ps_tmp.shape[1]))\n",
    "date_frame = []\n",
    "\n",
    "for t in range(len(files)):\n",
    "    print(files[0])\n",
    "    date_frame.append(datetime.strptime(files[t][5:18],'%Y%m%d.t%Hz'))\n",
    "    try:\n",
    "        ds = xr.open_dataset(files[t],engine='cfgrib',\n",
    "                            backend_kwargs=dict(filter_by_keys={'stepType': 'instant', 'typeOfLevel': 'surface'}))\n",
    "        ps = ds.sp.sel(latitude=slice(axis_bound[0],axis_bound[1]),longitude=slice(axis_bound[2]+360,axis_bound[3]+360))\n",
    "        ps_acqu[t,:,:] = ps.values   \n",
    "    except:\n",
    "        print('ERROR file: '+files[t])\n",
    "        ps_acqu[t,:,:] = np.nan\n",
    "\n",
    "# convert into xarray \n",
    "ps_acqu_xr = xr.DataArray(ps_acqu,dims=('time','latitude','longitude')\n",
    "                            ,coords=(date_frame,ps.latitude,ps.longitude-360),name='ps')\n",
    "#pwat_acqu_xr.to_netcdf('/data2/willytsai/InSAR_HRRR/HRRR_data/t02z/merged/HRRR_pwat_NEVADA.nc')\n",
    "ps_ds = ps_acqu_xr.to_dataset(name='ps')\n",
    "ps_ds.to_netcdf('/data2/willytsai/InSAR_HRRR/HRRR_data/t02z/merged/HRRR_Psfc_NEVADA.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
